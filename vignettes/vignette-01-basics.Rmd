---
title: "A basic ABC analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A basic ABC analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
slendr_present <- slendr::check_dependencies(python = TRUE, slim = TRUE, quit = FALSE)

knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>",
  fig.align = "center",
  fig.width = 8,
  fig.height = 5,
  dpi = 80,
  eval = slendr_present
)

data_path <- here::here("inst/examples/basics_abc.rds")

devtools::load_all()
devtools::load_all("~/Projects/slendr")
```

```{r, echo=FALSE, message=FALSE}
library(demografr)
library(slendr)

init_env()

SEED <- 42
set.seed(SEED)
```

```{r, eval=!file.exists(data_path), echo=FALSE, message=FALSE}
popA <- population("popA", time = 1, N = 2000)
popB <- population("popB", time = 2000, N = 800, parent = popA)
popC <- population("popC", time = 6000, N = 9000, parent = popB)
popD <- population("popD", time = 8000, N = 4000, parent = popC)

gf <- gene_flow(from = popB, to = popC, start = 9000, end = 9301, rate = 0.1)

example_model <- compile_model(
  populations = list(popA, popB, popC, popD), gene_flow = gf,
  generation_time = 1,
  simulation_length = 10000
)

ts <- msprime(example_model, sequence_length = 200e6, recombination_rate = 1e-8, random_seed = SEED) %>%
  ts_mutate(1e-8, random_seed = SEED)

samples <- slendr::ts_names(ts, split = "pop")
A <- samples["popA"]
B <- samples["popB"]
C <- samples["popC"]
D <- samples["popD"]

observed_diversity <- ts_diversity(ts, sample_sets = samples)
observed_divergence <- ts_divergence(ts, sample_sets = samples)

# I keep forgetting the rules for the symmetry of f4 quadruplets so let's double check that
# - generate all quadruples:
# perms <- combinat::permn(c(A, B, C, D))
# - compute theoretical values of all possible f4 statistics
# all_f4s <- lapply(perms, function(p) {
#   ts_f4(ts, p[1], p[2], p[3], p[4], mode = "branch")
# }) %>% do.call(rbind, .) %>% dplyr::arrange(abs(f4)) %>% as.data.frame()

# compute only unique f4 stats (up to a sign)
observed_f4 <- rbind(
  ts_f4(ts, A, B, C, D)
  # , ts_f4(ts, A, C, B, D),
  # ts_f4(ts, A, D, B, C)
)

write.table(observed_diversity, file = here::here("inst/examples/observed_diversity.tsv"),
            sep = "\t", row.names = FALSE, quote = FALSE)
write.table(observed_divergence, file = here::here("inst/examples/observed_divergence.tsv"),
            sep = "\t", row.names = FALSE, quote = FALSE)
write.table(observed_f4, file = here::here("inst/examples/observed_f4.tsv"),
            sep = "\t", row.names = FALSE, quote = FALSE)
```

⚠️⚠️⚠️

**Note:** The _demografr_ R package is still under active development. As a result, its documentation is in a draft stage at best. Typos, inconsistencies, and other issues are unfortunately expected.

⚠️⚠️⚠️

This vignette contains an expanded version of the basic ABC inference example from the [homepage](https://bodkan.net/demografr/) of _demografr_. It walks through the process of setting up a _demografr_ ABC pipeline step by step.

## Introduction

Imagine that we sequenced genomes of individuals from populations "popA", "popB", "popC", and "popD".

Let's also assume that we know that the three populations are phylogenetically related in the following way but we don't know anything else (i.e., we have no idea about the values of $N_e$, split times, or gene-flow rates):

```{r ape_tree, echo=FALSE, fig.width=5, fig.height=3.5}
par(mar = c(0, 0, 0, 0))
tree <- ape::read.tree(text="(popA,(popB,(popC,popD)));")
plot(tree)
arrows(2.5, 2, 2.5, 3, col="blue")
```

After sequencing the genomes of individuals from these populations, we computed nucleotide diversity in these populations as well as their pairwise genetic divergence and a one $f_4$ statistic, observing the following values of these summary statistics (which we saved in standard R data frames&mdash;perhaps saved by software we used for computing these from empirical sequence data):

1. Nucleotide diversity in each population:

```{r}
observed_diversity <- read.table(system.file("examples/observed_diversity.tsv", package = "demografr"), header = TRUE)

observed_diversity
```

2. Pairwise divergence d_X_Y between populations X and Y:

```{r}
observed_divergence <- read.table(system.file("examples/observed_divergence.tsv", package = "demografr"), header = TRUE)

observed_divergence
```

3. Value of the following $f_4$-statistic:

```{r}
observed_f4  <- read.table(system.file("examples/observed_f4.tsv", package = "demografr"), header = TRUE)

observed_f4
```

**Now let's develop a simple ABC pipeline which will infer the posterior distributions of two sets of parameters we are interested in: $N_e$ of each population lineage, as well as split times between our populations of interest.**

## Developing an ABC pipeline

Let's begin by loading _demografr_ together with the R package [_slendr_](https://www.slendr.net/) on which _demografr_ relies on for building and simulating demographic models.

```{r, message=FALSE}
library(demografr)
library(slendr)

# we also have to activate slendr's internal environment for tree sequences
# simulation and analysis
init_env()

# setup parallelization across all CPUs
library(future)
plan(multisession, workers = availableCores())
```

For the purpose of the ABC analysis below, we will bind all statistics in an R list, naming them appropriately. The names of each statistic (here "diversity" and "divergence") have meaning and are quite important for later steps:

```{r}
observed <- list(
  diversity  = observed_diversity,
  divergence = observed_divergence,
  f4         = observed_f4
)
```

### 1. Setting up a "scaffold" model

The first step in a _demografr_ ABC analysis is setting up a "scaffold" model&mdash;a _slendr_ function which will return a compiled _slendr_ model as its output, and which will accept the model parameters in form of normal R function arguments. In our simple examples, we will define the following function:

```{r}
model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {
  popA <- population("popA", time = 1,    N = Ne_A)
  popB <- population("popB", time = T_AB, N = Ne_B, parent = popA)
  popC <- population("popC", time = T_BC, N = Ne_C, parent = popB)
  popD <- population("popD", time = T_CD, N = Ne_D, parent = popC)

  gf <- gene_flow(from = popB, to = popC, start = 9000, end = 9301, rate = gf_BC)

  model <- compile_model(
    populations = list(popA, popB, popC, popD), gene_flow = gf,
    generation_time = 1, simulation_length = 10000,
    direction = "forward", serialize = FALSE
  )

  samples <- schedule_sampling(
    model, times = 10000,
    list(popA, 25), list(popB, 25), list(popC, 25), list(popD, 25),
    strict = TRUE
  )

  # when sampling schedule is used, both model and samples must be
  # returned by the model function
  return(list(model, samples))
}
```

### 2. Setting up priors

We are interested in estimating the $N_e$ of all populations and their split times. _demografr_ makes this very easy using a familiar symbolic formula syntax in R:

```{r}
priors <- list(
  Ne_A  ~ runif(100, 10000),
  Ne_B  ~ runif(100, 10000),
  Ne_C  ~ runif(100, 10000),
  Ne_D  ~ runif(100, 10000),

  T_AB  ~ runif(1,    4000),
  T_BC  ~ runif(3000, 9000),
  T_CD  ~ runif(5000, 10000),

  gf_BC ~ runif(0, 1)
)
```

In an ABC simulation step below, the formulas are used to draw the values of each parameter from specified distributions (in this case, all uniform distributions across a wide range of parameter values).

**For more detail into how _demografr_'s prior sampling formulas work (and why), take a look [here](vignette-02-priors.html).

### 3. Defining summary statistics

Each run of a _demografr_ ABC simulation internally produces a tree sequence as an output. Because tree sequence represents an efficient, succint representation of the complete genealogical history of a set of samples, it is possible to compute population genetic statistics directly on the tree sequence without having to first save each simulation output to disk for computation in different software. Thanks to _slendr_'s library of [tree-sequence functions](https://www.slendr.net/reference/index.html#tree-sequence-statistics) serving as an R interface to the [_tskit_ module](https://tskit.dev/tskit/docs/stable/stats.html), you can specify summary statistics to be computed for ABC using plain and simple R code.

In our example, because we computed nucleotide diversity and pairwise divergence in the individuals sequenced from populations "p1", "p2", and "p3", we will define the following functions. Crucially, when run on a tree-sequence object, they will produce an output data frame in the format analogous to the empirical statistics shown in data frames `diversity` and `divergence` above:

```{r}
compute_diversity <- function(ts) {
  samples <- ts_names(ts, split = "pop")
  ts_diversity(ts, sample_sets = samples)
}
compute_divergence <- function(ts) {
  samples <- ts_names(ts, split = "pop")
  ts_divergence(ts, sample_sets = samples)
}
compute_f4 <- function(ts) {
  samples <- ts_names(ts, split = "pop")
  A <- samples["popA"]; B <- samples["popB"]
  C <- samples["popC"]; D <- samples["popD"]
  ts_f4(ts, A, B, C, D)
}

functions <- list(
  diversity  = compute_diversity,
  divergence = compute_divergence,
  f4         = compute_f4
)
```

Crucially, the outputs of these summary functions _must_ match the format of the observed summary statistics (i.e., the data frames produced must have the same format). This minor inconvenience during ABC setup saves us the headache of having to match values of statistics between observed and simulated data during ABC inference itself.

Of course, having to run ABC simulations in order to check that the summary functions have been correctly defined would be slow and potentially costly in terms of wasted computation. To speed this process up, _demografr_ provides a helper function `simulate_model()` which allows you to simulate a single tree sequence object from the specified model. You can then use that tree sequence object to develop (and test) your summary functions before proceeding further, like this:

```{r}
ts <- simulate_model(model, priors, sequence_length = 1e6, recombination_rate = 1e-8)
```

With this `ts` object, we can, for instance, test that our `compute_f4` summary function is defined correctly (meaning that it returns $f_4$` statistics table formatted in exactly the same way as the observed table above):

```{r}
functions$f4(ts)
```

Looks good! (We have zero $f_4$ values because we didn't specify mutation rate in `simulate_model`, as we were only interested in the compatibility of the formats and dimensions of both simulated and observed $f_4$ tables). Of course, in your analysis pipeline, you might (should!) check that all of your summary functions are set up correctly.

### 4. ABC simulations

Having defined the scaffold model, a set of priors for our parameters of interest ($N_e$ and split times), as well as two summary statistic functions, we can plug all this information into the function `simulate_abc()`.

Before we run a potentially computationally costly simulations, it is a good idea to validate the ABC components we have so far assembled using the function `validate_abc()`. This provides much deeper correctness checks beyond the simple testing of the summary functions as we did above.

```{r}
validate_abc(model, priors, functions, observed)
```

Having verified that all model components are set up correctly, we can proceed to the ABC simulations themselves, using _demografr_'s function `simulate_abc()`:

```{r, echo=FALSE, eval=TRUE}
tstart <- Sys.time()
```

```{r, eval=!file.exists(data_path)}
data <- simulate_abc(
  model, priors, functions, observed, iterations = 10000,
  sequence_length = 50e6, recombination_rate = 1e-8, mutation_rate = 1e-8
)
```

```{r, echo=FALSE, eval=TRUE}
tend <- Sys.time()
tdelta <- as.numeric(difftime(tend, tstart, units = "secs"))
ncores <- future::availableCores()
```

```{r, echo=FALSE, eval=!file.exists(data_path)}
saveRDS(tdelta, here::here("inst/examples/basics_tdelta.rds"))
saveRDS(ncores, here::here("inst/examples/basics_ncores.rds"))
```

```{r, echo=FALSE, eval=file.exists(data_path)}
tdelta <- readRDS(here::here("inst/examples/basics_tdelta.rds"))
ncores <- readRDS(here::here("inst/examples/basics_ncores.rds"))
```

```{r, echo=FALSE, eval=TRUE}
hours <- floor(tdelta / 3600)
minutes <- floor((tdelta - hours * 3600) / 60)
seconds <- round(tdelta - hours * 3600 - minutes * 60)
```

**The total runtime for the ABC simulations was `r paste(hours, "hours", minutes, "minutes", seconds, "seconds")` parallelized across `r ncores` CPUs.**

At this point we have generated summary statistics for simulations of models using parameters drawn from our priors. In the next step, we can finally do inference of our parameters.

### 5. ABC inference

Having all the information about observed and simulated data bound in a single R object `data`, we can finally perform the ABC inference. _demografr_ includes a convenient function `run_abc()` which reformats the simulated and observed data in a format required by the R package [_abc_](https://cran.r-project.org/package=abc) and internally calls its function `abc()`.

Note that `run_abc` is just convenience wrapper around the `abc()` function in the package _abc_`, saving us a little work juggling the necessary matrices manually. As such, all parameters of the function `abc()` can be provided to `run_abc()`, which will then pass them on appropriately.

```{r, eval=!file.exists(data_path), echo=FALSE}
abc <- run_abc(data, engine = "abc", tol = 0.01, method = "neuralnet")
```

```{r, eval=!file.exists(data_path), echo=FALSE}
saveRDS(abc, data_path)
```

```{r, eval=file.exists(data_path), echo=FALSE}
abc <- readRDS(data_path)
```

### 6. Posterior predictive check

Before we proceed with inferring values of the model parameters from their posterior distributions, we should check whether our model can actually produce summary statistics which match the statistics observed in the empirical data.

In order to do this, we can use _demografr_'s `predict()` method which accepts two mandatory function arguments: the first is the `abc` object generated by the `run_abc()` function (and contains, among other things, the information about the inferred posteriors), and the number of draws to take from the multidimensional posterior distribution of the parameters:

```{r}
# because we set up a parallelization plan() above, the predictions are
# computed in parallel across all available CPUs
predictions <- predict(abc, samples = 1000)
```

If we take a closer look at the produced result, we see that it's a data frame object with several special columns (so-called ["list columns"](https://dcl-prog.stanford.edu/list-columns.html)). Those columns contain nested data frames with the values of tree-sequence summary statistics computed for each combination of the parameter values. Because this data has the same format as the output of the function `simulate_grid()` (in fact, internally it _is_ produced by this function), see the vignette on [grid simulations](vignette-03-grids.html) for more detail how to analyse this.

In order to perform a detailed analysis of the posterior predictive check results for individual (or all) summary statistics, you can use the function `extract_prediction()`. A convenient alternative to check the results visually is provided by the function `plot_prediction()`. For instance, we can take a look at the distributions of divergences produced from the parameter posterior like this:

```{r, postpred_diversity}
plot_prediction(predictions, "diversity")
```

```{r, postpred_divergence}
plot_prediction(predictions, "divergence")
```

```{r, postpred_f4}
plot_prediction(predictions, "f4")
```

**Nice! It appears that the posterior from our simplistic model captures the observed summary statistics (dashed vertical lines) quite well.**

(To make evaluation a little bit easier, there's an option `file =` which instructs `plot_prediction` to save a figure to disk instead of plotting it using a graphical device&mdash;useful for work on remote servers!).

**For more details on possible downstream validation and troubleshooting analyses, please see [this vignette](vignette-06-diagnostics.html).**

### 7. Posterior analysis

#### Extracting posterior summary tables

Now that we have the ABC output object ready and have more or less convinced ourselves that our model can capture the summary statistics we've chosen via posterior predictive checks, we can proceed with parameter inference.

First, we can get a data frame with summary statistics of the posterior distributions of our parameters. For instance, we can easily read the maximum a posteriori probability (MAP) of the parameters in the row labelled "Mode:":

```{r}
extract_summary(abc)
```

Because large tables can get a little hard to read, it is possible to subset to only a specific _type_ of parameter:

```{r}
extract_summary(abc, param = "Ne")
```

```{r}
extract_summary(abc, param = "T")
```

Alternatively, we can also extract the posterior summary for a single parameter like this:

```{r}
extract_summary(abc, param = "Ne_D")
```

#### Visualizing posterior distributions of parameters

Because a chart is always more informative than a table, we can easily get a visualization of our posteriors using the function `plot_posterior()`:

```{r, posterior_Ne, fig.width=8, fig.height=5}
plot_posterior(abc, param = "Ne") + ggplot2::coord_cartesian(xlim = c(0, 10000))
```

Excellent! It looks like we got really nice and informative posterior distributions of $N_e$ values!

Similarly, we get nice and informative posterior distributions of split times:

```{r, posterior_Tsplit, fig.width=8, fig.height=5}
plot_posterior(abc, param = "T") + ggplot2::coord_cartesian(xlim = c(0, 10000))
```

And the same is true for the gene-flow rate:

```{r, posterior_gf, fig.width=8, fig.height=5}
plot_posterior(abc, param = "gf") + ggplot2::coord_cartesian(xlim = c(0, 1))
```

Because the internals of _demografr_ ABC objects are represented by standard objects created by the _abc_ package, we have many of the standard diagnostics functions of the _abc_ R package at our disposal. For instance, we can use the standard function `plot()` to verify that the posterior (red line) for one of the split times matches the prior (dashed line), suggesting that the data we provided (nucleotide diversity and pairwise divergence) are not sufficient statistics to capture enough information about population divergences.

```{r, diagnostic_Tsplit, fig.width=10, fig.height=7}
plot(abc, param = "T_BC")
```

In contrast, we can see that there most definitely is sufficient information encoded in the summary statistics to tell us quite a bit about the $N_e$ of our populations:

```{r, diagnostic_Ne, fig.width=10, fig.height=7}
plot(abc, param = "Ne_B")
```

```{r, diagnostic_hist_Ne, fig.width=10, fig.height=7}
hist(abc, param = "gf")
```
