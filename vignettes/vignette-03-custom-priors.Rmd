---
title: "Detailed discussion on priors"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Detailed discussion on priors}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center"
)

devtools::install(".", upgrade = FALSE)
```

## Introduction

In a [previous vignette](vignette-02-scaffold-models.html), we looked at how _demografr_ allows a complete customization of what a "scaffold model" can look like and that basically any functions which returns a compiled slendr model can serve as such a scaffold, with its function arguments representing parameters which need to be assigned priors.

In this vignette, we will take things even further, showing that in addition to standard prior sampling expression using familiar functions such as `runif` or `rnorm`, any function which follows certain constraints can serve as a prior.

The example we will use here will focus on trying to infer phylogenetic relationships between populations, using prior distributions on trees themselves.

Again, let's begin by loading a couple of libraries and setting up parallelization for inference:

```{r, message=FALSE}
library(dplyr)
library(readr)

# R packages for working with phylogenetic trees
library(ape)
library(phangorn)

library(slendr)
library(demografr)

# my Mac has 10 cores, feel free to adjust this
future::plan("multisession", workers = 10)
```

We then load  summary statistics computed from "sequenced" real data:

```{r, message=FALSE}
diversity_df <- read_tsv(system.file("examples/01_diversity.tsv", package = "demografr"))
divergence_df <- read_tsv(system.file("examples/01_divergence.tsv", package = "demografr"))

observed <- list(diversity = diversity_df, divergence = divergence_df)
observed
```

And we also define corresponding tree-sequence-based summary statistics using functions that operate on simulated tree-sequence objects:

```{r}
compute_diversity <- function(ts) {
  samples <- sample_names(ts, split = TRUE)
  ts_diversity(ts, sample_sets = samples) %>%
    mutate(stat = paste0("pi_", set)) %>%
    select(stat, value = diversity)
}
compute_divergence <- function(ts) {
  samples <- sample_names(ts, split = TRUE)
  ts_divergence(ts, sample_sets = samples) %>%
    mutate(stat = sprintf("d_%s_%s", x, y)) %>%
    select(stat, value = divergence)
}
functions <- list(diversity = compute_diversity, divergence = compute_divergence)
```



### How do priors work in _demografr_?

Our ABC model will use standard priors on $N_e$ and divergence times. As in our other vignettes, we will use uniform distributions to do this.

Recall a function `runif` which is used in the following way to sample a single number:

```{r}
runif(n = 1, min = 1, max = 1000)
```

To save us a bit of typing and to make prior definitions a bit more consise, _demografr_ uses the following syntax to define model parameters:

```{r}
prior <- Ne_popXYZ ~ runif(1, 1000)
```

This formula-based syntax, which some of you will be familiar from fitting linear models (i.e. `lm(response ~ pred1 + pred2 + pred3)`) does not actually perform any sampling. It merely represents a readable way to encode probabilistic sampling statements. To demonstrate this, typing the prior in the R console simply returns the statement:

```{r}
prior
```

You might also notice that the right-hand side of the prior sampling expression above `Ne_popXYZ ~ runif(0, 1000)` does not represent a valid statement:

```{r}
runif(1, 1000)
```

That is not a problem, because sampling from priors (which _demografr_ performs internally during ABC simulations) is taken care of automatically, converting the above function call into proper sampling statement:

```{r}
( Ne_popXYZ ~ runif(1, 1000) ) %>% sample_prior()
```

### How to define custom priors?

Now that we have gone through how priors work using standard R functions like `runif`, how can we define our own prior distributions?

In short, _any_ function that returns a single value (of whatever type! see below) can serve as a prior. The only requirement is that the first argument of the function must be called `n`. This is purely for formal reasons and to make the prior sampling interface of _demografr_ in line with the interface of all functions of the `r[unif/norm/pois/exp/...]` type that we know from R (i.e. the full interface of the function `rnorm` is `rnorm(n, mean = 0, sd = 1)`). Except for the first argument `n`, you can use whatever function arguments you want.

Let's consider a uniform prior over tree genealogies with $n$ tips by defining a simple R function like this:

```{r}
topologies <- allTrees(n = 4, rooted = TRUE, tip.label = c("popA", "popB", "popC", "popD"))

sample_topology <- function(n, topologies) {
  sample(seq_along(topologies), size = 1)
}
```

Note that as explained in the paragraph above, the function has a formal argument `n` but does not actually use it. The argument which _is_ used internally is `ntips`, describing the number of leaves of the tree to be generated by the function `rtopology()` from the package _ape_.

Using our tree sampling function we can now define a uniform prior over all phylogenetic trees of a given number of leaves:

```{r}
priors <- list(
  i       ~ sample_topology(topologies),
  Ne_popA ~ 1000,
  Ne_popB ~ 3000,
  Ne_popC ~ 10000,
  Ne_popD ~ 5000
)
```

### Defining a model

Having defined our priors (here really just one uniform prior over all topologies), we define a custom scaffold model building function which will accept an integer value `i` as its parameter&mdash;this will be populated by numbers sampled from the `priors`. Additionally, we also provide a second function argument with the list of all topologies. We do this for computational efficiency (so that the topologies don't have to be generated every time this generating function will be called during ABC simulations) but it is also a good idea from a software engineering point of view (making the whole function nicely self-contained).

```{r}
model <- function(i, topologies) {
  tree <- topologies[[i]]
  tree_model(tree, N = 1000, time_span = 10000, generation_time = 1)
}
```

Hopefully, it should be clear how much more flexibility this kind of set up gives us in defining scaffold models for an ABC analysis. Of course, running this function with a given set of parameters compiles a standard _slendr_ model, no surprises there.  This makes it easy to verify that the generating function is set up correctly, like we do in the following code chunk by providing arbitrary values of our parameters:

We can convince ourselves that the scaffold-building function works correctly by testing what would happen if it received a single value sampled from a prior, let's say value `i = 7`:


```{r, slendr_model3, fig.width=5, fig.height=3, fig.align="center"}
test_model <- model(
  i = 7,      # let's say this is the value that was sampled from the prior
  topologies  # this argument provides all topologies to be sampled over
)

plot_model(test_model)
```

Additionally, it is always worth to validate the ABC setup to catch issues as early as possible:

```{r}
validate_abc(model, priors, functions, observed,
             model_args = list(topologies = topologies))
```

Having convinced ourselves that the ABC model components are correctly configured, we would proceed with inference (again, we're not going to run the full ABC pipeline here because it would take a lot of time to get useful posteriors):

```{r, eval=FALSE}
# first simulate data
data <- simulate_abc(
  model, priors, functions, observed,
  iterations = 10000, sequence_length = 1e6, recombination_rate = 1e-8, mutation_rate = 1e-8,
  model_args = list(topologies = topologies)
)

# then perform ABC inference
abc <- perform_abc(data, tolerance = 0.005, method = "neuralnet")
```
