[{"path":"https://bodkan.net/demografr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Martin Petr Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A basic ABC workflow","text":"Imagine sequenced genomes individuals populations “”, “B”, “C”, “D”. Let’s also assume know populations phylogenetically related following way don’t know anything else (.e., idea values NeN_e, split times, gene-flow proportions):  sequencing genomes individuals populations, computed nucleotide diversity populations well pairwise genetic divergence one f4f_4 statistic, observing following values summary statistics (saved standard R data frames—perhaps saved software used computing empirical sequence data): Nucleotide diversity population: Pairwise divergence d_X_Y populations X Y: Value following f4f_4-statistic: Now let’s develop simple ABC pipeline infer posterior distributions two sets parameters interested : NeN_e population lineage, well split times populations interest, gene-flow proportion.","code":"observed_diversity <- read.table(system.file(\"examples/basics_diversity.tsv\", package = \"demografr\"), header = TRUE)  observed_diversity #>   set    diversity #> 1   A 8.030512e-05 #> 2   B 3.288576e-05 #> 3   C 1.013804e-04 #> 4   D 8.910909e-05 observed_divergence <- read.table(system.file(\"examples/basics_divergence.tsv\", package = \"demografr\"), header = TRUE)  observed_divergence #>   x y   divergence #> 1 A B 0.0002378613 #> 2 A C 0.0002375761 #> 3 A D 0.0002379385 #> 4 B C 0.0001088217 #> 5 B D 0.0001157056 #> 6 C D 0.0001100633 observed_f4  <- read.table(system.file(\"examples/basics_f4.tsv\", package = \"demografr\"), header = TRUE)  observed_f4 #>   W X Y Z            f4 #> 1 A B C D -3.262146e-06"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"developing-an-abc-pipeline","dir":"Articles","previous_headings":"","what":"Developing an ABC pipeline","title":"A basic ABC workflow","text":"Let’s begin loading demografr together R package slendr demografr relies building simulating demographic models. purpose ABC inference, bind statistics R list, naming appropriately. names statistic (“diversity”, “divergence”, “f4”) meaning quite important later steps:","code":"library(demografr) library(slendr)  # we also have to activate slendr's internal environment for tree sequences # simulation and analysis init_env()  # setup parallelization across all CPUs library(future) plan(multisession, workers = availableCores()) observed <- list(   diversity  = observed_diversity,   divergence = observed_divergence,   f4         = observed_f4 )"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"setting-up-a-scaffold-model","dir":"Articles","previous_headings":"Developing an ABC pipeline","what":"1. Setting up a “scaffold” model","title":"A basic ABC workflow","text":"first step demografr ABC analysis setting “scaffold” model—slendr function produce compiled slendr model object, accept model parameters form normal R function arguments. simple examples, define following function:","code":"model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {   A <- population(\"A\", time = 1,    N = Ne_A)   B <- population(\"B\", time = T_AB, N = Ne_B, parent = A)   C <- population(\"C\", time = T_BC, N = Ne_C, parent = B)   D <- population(\"D\", time = T_CD, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf_BC)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\", serialize = FALSE   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 25), list(B, 25), list(C, 25), list(D, 25),     strict = TRUE   )    # when a specific sampling schedule is to be used, both model and samples   # must be returned by the function   return(list(model, samples)) }"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"setting-up-priors","dir":"Articles","previous_headings":"Developing an ABC pipeline","what":"2. Setting up priors","title":"A basic ABC workflow","text":"interested estimating NeN_e populations, split times, gene-flow proportion means need specify priors. demografr makes easy using readable syntax: ABC simulation step , formulas used draw values parameter specified distributions (case, uniform distributions). detail demografr’s prior sampling formulas work (), take look vignette.","code":"priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"defining-summary-statistics","dir":"Articles","previous_headings":"Developing an ABC pipeline","what":"3. Defining summary statistics","title":"A basic ABC workflow","text":"run demografr ABC simulation internally produces tree sequence. tree sequence represents efficient, succint representation complete genealogical history set samples, possible compute population genetic statistics directly tree sequence without first save outcome simulation disk computation different software. Thanks slendr’s library tree-sequence functions serving R interface tskit module, can specify summary statistics computed ABC using normal R code. example, computed nucleotide diversity, pairwise divergence, f4f_4 sequence data, define following summary statistic functions. Crucially, run tree-sequence object, produce data frame format analogous empirical statistics shown data frames observed summary statistics . important point: observed statistic must format (dimension) data frames produced simulation summary functions. minor inconvenience ABC setup saves us headache match values statistics observed simulated data ABC inference . course, run ABC simulations order check summary functions correctly defined slow potentially costly terms wasted computation. speed process , demografr provides helper function simulate_model() allows us simulate single tree-sequence object specified model. can use tree sequence develop (test) summary functions proceeding , like : ts object, can, instance, test compute_f4 summary function defined correctly (meaning returns f4f_4` statistics table formatted exactly way observed table ): Looks good! (zero f4f_4 values didn’t specify mutation rate simulate_model, interested compatibility formats dimensions simulated observed f4f_4 tables). course, pipeline, might (!) check summary functions set correctly.","code":"compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) } compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) } compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  functions <- list(   diversity  = compute_diversity,   divergence = compute_divergence,   f4         = compute_f4 ) ts <- simulate_model(model, priors, sequence_length = 1e6, recombination_rate = 1e-8) ts #> ╔═══════════════════════════╗ #> ║TreeSequence               ║ #> ╠═══════════════╤═══════════╣ #> ║Trees          │      1,782║ #> ╟───────────────┼───────────╢ #> ║Sequence Length│  1,000,000║ #> ╟───────────────┼───────────╢ #> ║Time Units     │generations║ #> ╟───────────────┼───────────╢ #> ║Sample Nodes   │        200║ #> ╟───────────────┼───────────╢ #> ║Total Size     │  383.2 KiB║ #> ╚═══════════════╧═══════════╝ #> ╔═══════════╤═════╤═════════╤════════════╗ #> ║Table      │Rows │Size     │Has Metadata║ #> ╠═══════════╪═════╪═════════╪════════════╣ #> ║Edges      │7,981│249.4 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Individuals│  100│  2.8 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Migrations │    0│  8 Bytes│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Mutations  │    0│ 16 Bytes│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Nodes      │2,360│ 64.5 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Populations│    4│331 Bytes│         Yes║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Provenances│    1│  2.6 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Sites      │    0│ 16 Bytes│          No║ #> ╚═══════════╧═════╧═════════╧════════════╝ functions$f4(ts) #> # A tibble: 1 × 5 #>   W     X     Y     Z        f4 #>   <chr> <chr> <chr> <chr> <dbl> #> 1 A     B     C     D         0"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"abc-simulations","dir":"Articles","previous_headings":"Developing an ABC pipeline","what":"4. ABC simulations","title":"A basic ABC workflow","text":"defined scaffold model, set priors parameters interest (NeN_e, split times, gene-flow proportion), well two summary statistic functions, can integrate information function simulate_abc(). run potentially computationally costly simulations, good idea validate ABC components far assembled using function validate_abc(). provides much elaborate correctness checks beyond simple testing summary functions . verified model components set correctly, can proceed ABC simulations , using demografr’s function simulate_abc(): total runtime ABC simulations 0 hours 17 minutes 22 seconds parallelized across 96 CPUs. point generated summary statistics simulations models using parameters drawn priors. next step, can finally inference parameters.","code":"validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 1e-8) #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne_A ✅ #>   - Ne_B ✅ #>   - Ne_C ✅ #>   - Ne_D ✅ #>   - T_AB ✅ #>   - T_BC ✅ #>   - T_CD ✅ #>   - gf_BC ✅ #> --------------------------------------------------------------------- #> The model is a slendr function #> --------------------------------------------------------------------- #> Checking the return statement of the model function... ✅ #> --------------------------------------------------------------------- #> Checking the presence of required model function arguments...--------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #>   - divergence ✅ #>   - f4 ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #>   - divergence [data frame] ✅ #>   - f4 [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup! data <- simulate_abc(   model, priors, functions, observed, iterations = 10000,   sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8 )"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"abc-inference","dir":"Articles","previous_headings":"Developing an ABC pipeline","what":"5. ABC inference","title":"A basic ABC workflow","text":"information observed simulated data bound single R object data, can finally infer posterior distribution model parameters using ABC. demografr includes convenient function run_abc() reformats simulated observed data format required R package abc internally calls function abc(). Note run_abc just convenience wrapper around abc() function package abc, saving us lot work reformatting data otherwise necessary. , parameters functionabc()can provided torun_abc()`, pass appropriately.","code":"abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"posterior-predictive-check","dir":"Articles","previous_headings":"Developing an ABC pipeline","what":"6. Posterior predictive check","title":"A basic ABC workflow","text":"proceed inferring values model parameters posterior distributions, check whether model can actually produce summary statistics match statistics observed empirical data. order , can use demografr’s predict() method accepts two mandatory function arguments: first abc object generated run_abc() function (containing, among things, information inferred posteriors), number draws take posterior distribution parameters: take closer look produced result, see ’s data frame object several special columns (-called “list columns”). columns contain nested data frames values tree-sequence summary statistics computed combination parameter values. data format output function simulate_grid() (fact, internally produced function), see vignette grid simulations detail analyse . order examine posterior predictive check results individual () summary statistics, can use function extract_prediction(). convenient alternative check results visually provided function plot_prediction(). instance, can take look distributions divergences produced parameter posterior like :    Nice! appears posterior simplistic model captures observed summary statistics (dashed vertical lines) quite well. (make evaluation little bit easier, ’s option file = instructs plot_prediction save figure disk instead plotting using graphical device—useful work remote servers!). details additional downstream validation troubleshooting options, please see vignette.","code":"# because we set up a parallelization plan() above, the predictions are # computed in parallel across all available CPUs predictions <- predict(abc, samples = 1000) plot_prediction(predictions, \"diversity\") plot_prediction(predictions, \"divergence\") plot_prediction(predictions, \"f4\")"},{"path":[]},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"extracting-posterior-summary-tables","dir":"Articles","previous_headings":"Developing an ABC pipeline > 7. Extracting esimated parameters","what":"Extracting posterior summary tables","title":"A basic ABC workflow","text":"Now ABC output object ready less convinced model can capture summary statistics ’ve chosen via posterior predictive checks, can proceed parameter inference. First, can get data frame summary statistics posterior distributions parameters. instance, can easily read maximum posteriori probability (MAP) parameters row labelled “Mode:”: large tables can get little hard read, possible subset specific type parameter: Alternatively, can also extract posterior summary single model parameter like :","code":"extract_summary(abc) #>                            Ne_A      Ne_B      Ne_C     Ne_D       T_AB #> Min.:                  1609.744  682.6193  7389.026 1846.029  -96.82908 #> Weighted 2.5 % Perc.:  1812.239  729.5846  7585.374 2691.913 1242.73702 #> Weighted Median:       2030.741  837.2673  8588.420 3785.385 1907.90411 #> Weighted Mean:         2019.638  841.6564  8674.207 3805.943 1949.07359 #> Weighted Mode:         2049.985  847.0022  8469.365 3642.722 1911.88919 #> Weighted 97.5 % Perc.: 2204.442  979.8260  9543.851 4742.401 2690.25909 #> Max.:                  2281.020 1038.0898 10965.790 5915.021 2921.08324 #>                            T_BC     T_CD       gf_BC #> Min.:                  5272.336 6608.244 -0.02143034 #> Weighted 2.5 % Perc.:  5630.022 7105.185  0.03373237 #> Weighted Median:       6133.605 7829.842  0.09864958 #> Weighted Mean:         6110.468 7814.700  0.10241672 #> Weighted Mode:         6236.457 7855.537  0.09655264 #> Weighted 97.5 % Perc.: 6603.022 8379.513  0.17629759 #> Max.:                  6838.022 8551.676  0.21388432 extract_summary(abc, param = \"Ne\") #>                            Ne_A      Ne_B      Ne_C     Ne_D #> Min.:                  1609.744  682.6193  7389.026 1846.029 #> Weighted 2.5 % Perc.:  1812.239  729.5846  7585.374 2691.913 #> Weighted Median:       2030.741  837.2673  8588.420 3785.385 #> Weighted Mean:         2019.638  841.6564  8674.207 3805.943 #> Weighted Mode:         2049.985  847.0022  8469.365 3642.722 #> Weighted 97.5 % Perc.: 2204.442  979.8260  9543.851 4742.401 #> Max.:                  2281.020 1038.0898 10965.790 5915.021 extract_summary(abc, param = \"T\") #>                              T_AB     T_BC     T_CD #> Min.:                   -96.82908 5272.336 6608.244 #> Weighted 2.5 % Perc.:  1242.73702 5630.022 7105.185 #> Weighted Median:       1907.90411 6133.605 7829.842 #> Weighted Mean:         1949.07359 6110.468 7814.700 #> Weighted Mode:         1911.88919 6236.457 7855.537 #> Weighted 97.5 % Perc.: 2690.25909 6603.022 8379.513 #> Max.:                  2921.08324 6838.022 8551.676 extract_summary(abc, param = \"gf_BC\") #>                              gf_BC #> Min.:                  -0.02143034 #> Weighted 2.5 % Perc.:   0.03373237 #> Weighted Median:        0.09864958 #> Weighted Mean:          0.10241672 #> Weighted Mode:          0.09655264 #> Weighted 97.5 % Perc.:  0.17629759 #> Max.:                   0.21388432"},{"path":"https://bodkan.net/demografr/articles/vignette-01-basics.html","id":"visualizing-posterior-distributions-of-parameters","dir":"Articles","previous_headings":"Developing an ABC pipeline > 7. Extracting esimated parameters","what":"Visualizing posterior distributions of parameters","title":"A basic ABC workflow","text":"chart always informative table, can easily get visualization posteriors using function plot_posterior():  Excellent! looks like got really nice informative posterior distributions NeN_e values! Similarly, get nice informative posterior distributions split times:  true gene-flow proportion:  internals demografr ABC objects represented standard objects created abc package, standard diagnostics functions abc R package disposal.    , numerous tools additional diagnostics, can learn .","code":"plot_posterior(abc, param = \"Ne\") + ggplot2::coord_cartesian(xlim = c(0, 10000)) plot_posterior(abc, param = \"T\") + ggplot2::coord_cartesian(xlim = c(0, 10000)) plot_posterior(abc, param  = \"gf\") + ggplot2::coord_cartesian(xlim = c(0, 1)) plot(abc, param = \"T_BC\") plot(abc, param = \"gf_BC\") hist(abc, param = \"Ne_D\")"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"one-trivial-option","dir":"Articles","previous_headings":"","what":"One trivial option","title":"Specifying prior distributions","text":"Possibly trivial solution problem R write something like following. Indeed, probabilistic inference R packages exactly : Python, might write object-oriented code like : question asked began drafting design demografr whether possible “elegantly”—less code closer actual mathematical notation.","code":"list(   list(\"Ne\", \"runif\", 1000, 10000),   list(\"geneflow\", \"runif\", 0, 1),   # (not sure how would one create a vector like T_i) ) import tensorflow_probability as tfp  # define random variables Ne = tfp.distributions.Uniform(low=1000., high=10000.) geneflow = tfp.distributions.Uniform(low=0., high=1.) T_split = tfp.distributions.Uniform(low=10., high=10000.)  # sample from the distributions Ne_sample = Ne.sample() geneflow_sample = geneflow.sample() T_split_sample = T_split.sample(5)"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"fancier-metaprogramming-solution","dir":"Articles","previous_headings":"","what":"Fancier metaprogramming solution","title":"Specifying prior distributions","text":"Despite “silly calculator language” (quote former colleague mine), R powerful functional programming language advanced metaprogramming options. paraphrase information Wikipedia: Metaprogramming programming technique computer programs ability treat programs data. means program can designed read, generate, analyze transform programs, even modify running. words, metaprogramming code writing code. mean practice R? might familiar syntax fitting linear models R: ~ operator creates -called “formula object”, captures expression provided user (relationship columns data frame, \"cyl\" \"mpg\"), can manipulated interpreted function formula passed . Importantly, type cyl ~ mpg R console, get thing back. doesn’t anything ! fact, type cyl mpg R console , get error. However, execute lm command , function uses R’s metaprogramming features interpret information formula extract appropriate information (column vectors \"cyl\" \"mpg\") data frame, perform necessary computation linear regression fit. context, one also say formula syntax provides domain-specific language encoding statistical modeling equations R. goal demografr, , provide similar functionality encoding prior sampling statements.","code":"head(mtcars) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 lm(cyl ~ mpg, data = mtcars) #>  #> Call: #> lm(formula = cyl ~ mpg, data = mtcars) #>  #> Coefficients: #> (Intercept)          mpg   #>     11.2607      -0.2525"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"how-to-use-this-for-the-problem-above","dir":"Articles","previous_headings":"","what":"How to use this for the problem above?","title":"Specifying prior distributions","text":"Imagine want write R interface something like : Ne∼Unif(1000,10000).N_e \\sim Unif(1000, 10000). Obviously, functions runif, rnorm, etc., generate number distribution: can also R, “free”, without anything else. Note expression evaluated! Formula simply object carrying bit syntax. Just demonstrated discussion formula used lm call, simply entering Ne ~ runif(1000, 10000) R console doesn’t anything . important, runif(1000, 10000) right valid R code. called lazy evaluation. R evaluate something time unless ’s “needed” time. opposite “eager evaluation” done something like Python C.","code":"runif(n = 1, min = 1000, max = 10000) #> [1] 9233.254 prior <- Ne ~ runif(1000, 10000)  prior #> Ne ~ runif(1000, 10000)"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"metaprogramming-in-r-in-practice","dir":"Articles","previous_headings":"","what":"Metaprogramming in R in practice","title":"Specifying prior distributions","text":"Metaprogramming often magic requiring lots complicated tools, basic metaprogramming R simple. can “manipulate” code give meaning? given formula, R function .list parses language expression smallest possible “atomic pieces”: called abstract syntax tree programming language design. Note works generally language expression (even much deeper): Although fut expressions like easier use proper metaprogramming tool function ast provided R package lobstr: Even haven’t heard AST , look closely result , notice captures expression (+ b) * (c - d / e) except dissassembled smallest possible atomic pieces decomposed via -called prefix notation. standard representation AST data structure (fact, simpler version obtained via .list thing).","code":"prior #> Ne ~ runif(1000, 10000) as.list(prior) #> [[1]] #> `~` #>  #> [[2]] #> Ne #>  #> [[3]] #> runif(1000, 10000) (a + b) * (c - d / e) lobstr::ast((a + b) * (c - d / e)) #> █─`*`  #> ├─█─`(`  #> │ └─█─`+`  #> │   ├─a  #> │   └─b  #> └─█─`(`  #>   └─█─`-`  #>     ├─c  #>     └─█─`/`  #>       ├─d  #>       └─e"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"back-to-demografr","dir":"Articles","previous_headings":"","what":"Back to demografr","title":"Specifying prior distributions","text":"Let’s now return original goal encoding prior sampling statements variable∼distribution\\textrm{variable} \\sim \\textrm{distribution}: can parse like : hope interpret way ’s compatible something like Ne∼Unif(1000,10000)N_e \\sim Unif(1000, 10000). demografr implements way parse prior sampling statement, automatically convert “invalid” expression: proper R statement used ABC simulation process.","code":"prior #> Ne ~ runif(1000, 10000) as.list(prior) #> [[1]] #> `~` #>  #> [[2]] #> Ne #>  #> [[3]] #> runif(1000, 10000) Ne ~ runif(1000, 10000) runif(n = 1, min = 1000, max = 10000)"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"sample_prior-function","dir":"Articles","previous_headings":"Back to demografr","what":"sample_prior() function","title":"Specifying prior distributions","text":"feature demografr implemented function sample_prior. Although function exported user space R console, shouldn’t need use work besides simple debugging priors: function takes formula statement (DLS encoding prior sampling events), parses individual components, simulates value random variable provided distribution function.","code":"library(demografr) sample_prior(Ne ~ runif(1000, 10000)) #> $variable #> [1] \"Ne\" #>  #> $value #> [1] 9433.679 sample_prior(Ne ~ runif(1000, 10000)) #> $variable #> [1] \"Ne\" #>  #> $value #> [1] 3575.256 sample_prior(Ne ~ runif(1000, 10000)) #> $variable #> [1] \"Ne\" #>  #> $value #> [1] 8474.029"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"sampling-random-vectors","dir":"Articles","previous_headings":"","what":"Sampling random vectors","title":"Specifying prior distributions","text":"provide support random vectors, demografr uses similar metaprogramming trick . Imagine syntax vectorized statements (T_split[5] demografr’s made syntax, R syntax!): Note expression one layer “deeper” plain T_split ~ runif(10, 10000). means “vector variables” demografr, need take care nesting:","code":"prior <- T_split[5] ~ runif(10, 10000) as.list(prior) #> [[1]] #> `~` #>  #> [[2]] #> T_split[5] #>  #> [[3]] #> runif(10, 10000) variable <- as.list(prior)[[2]] variable #> T_split[5] as.list(variable) #> [[1]] #> `[` #>  #> [[2]] #> T_split #>  #> [[3]] #> [1] 5"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"in-demografr-then","dir":"Articles","previous_headings":"Sampling random vectors","what":"In demografr then…","title":"Specifying prior distributions","text":"internally turns prior expression runif(n = 10, min = 10, max = 10000).","code":"sample_prior(T_split[5] ~ runif(10, 10000)) #> $variable #> [1] \"T_split\" #>  #> $value #> [1] 6421.038 5195.769 7368.517 1355.319 6573.353"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"final-result","dir":"Articles","previous_headings":"","what":"Final list of all priors","title":"Specifying prior distributions","text":"conclusion, using demografr’s features ’s possible define example prior sampling statements top vignette R code like : Take home messages: declarative! R code defines priors, doesn’t sample numbers! exact process metaprogramming accomplishes something don’t ever worry care user. processing sampling priors done internally (automatically) demografr running simulation replicates ABC, etc., like :","code":"priors <- list(   Ne         ~ runif(1000, 10000),   geneflow   ~ runif(0, 1),   T_split[5] ~ runif(10, 1000),   truth      ~ 42 ) data <- simulate_abc(model, <priors>, functions, observed, ...)"},{"path":[]},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"prior-parameter-templates","dir":"Articles","previous_headings":"","what":"Prior parameter templates","title":"Specifying prior distributions","text":"Imagine following slendr model function (hilariously overcomplicated, purely demonstration purposes!): functions huge number parameters, specify normal DSL described purposes ABC inference, write following monstrosity: second possibility re-parametrize function accept, instance, two pairs two vectors T N, one population. However, can also use demografr’s support ‘templated’ prior sampling expressions (lack better word). easiest way explain just write : priors like plugged either simulate_abc() simulate_model(), demografr tries match model function arguments prior names (, T_a... T_b...), assigning model function argument (.e., model parameter) appropriate prior sampling expression substituting ... left hand prior sampling statement. can read T_a... ~ <distribution> “sample parameter starting ‘T_a’ <distribution>. way, defining prior sampling expressions, ’re hindered complexity model function (handle vector indexing ’d vectorized prior sampling statements). demografr also provides means visualize entire prior distribution using numbers sampled . can helpful check previously defined prior sampling statements correctnes:","code":"library(slendr) init_env(quiet = TRUE)  model <- function(T_a1, T_a2, T_a3, T_a4, T_a5, T_b1, T_b2, T_b3, T_b4, T_b5, N_a, N_b) {   a1 <- population(\"a1\", time = T_a1, N = N_a)   a2 <- population(\"a2\", time = T_a2, N = N_a, parent = a1)   a3 <- population(\"a3\", time = T_a3, N = N_a, parent = a1)   a4 <- population(\"a4\", time = T_a4, N = N_a, parent = a1)   a5 <- population(\"a5\", time = T_a5, N = N_a, parent = a1)    b1 <- population(\"b1\", time = T_b1, N = N_b, parent = a1)   b2 <- population(\"b2\", time = T_b2, N = N_b, parent = b1)   b3 <- population(\"b3\", time = T_b3, N = N_b, parent = b1)   b4 <- population(\"b4\", time = T_b4, N = N_b, parent = b1)   b5 <- population(\"b5\", time = T_b5, N = N_b, parent = b1)    model <- compile_model(     list(a1, a2, a3, a4, a5, b1, b2, b3, b4, b5),     generation_time = 30,   )    return(model) } individual_priors <- list(   T_a1 ~ runif(1, 100000),   T_a2 ~ runif(1, 100000),   T_a3 ~ runif(1, 100000),   T_a4 ~ runif(1, 100000),   T_a5 ~ runif(1, 100000),   T_b1 ~ runif(50000, 100000),   T_b2 ~ runif(50000, 100000),   T_b3 ~ runif(50000, 100000),   T_b4 ~ runif(50000, 100000),   T_b5 ~ runif(50000, 100000),    N_a ~ runif(100, 1000),   N_b ~ runif(200, 7000) ) templated_priors <- list(   T_a... ~ runif(1,     100000),   T_b... ~ runif(50000, 100000),   N_a    ~ runif(10,    3000),   N_b    ~ runif(1000,  10000) ) plot_prior(individual_priors) plot_prior(individual_priors, facets = TRUE)"},{"path":"https://bodkan.net/demografr/articles/vignette-02-priors.html","id":"custom-functions","dir":"Articles","previous_headings":"Prior parameter templates","what":"Custom functions","title":"Specifying prior distributions","text":"DSL specification parameter priors also allows custom-defined prior distribution functions, just built-runif(), rnorm(), etc. instance, imagine function simulating sampling distribution loaded casino die, rcasino(): can use custom function exactly way standard R sampling functions. First, define prior sampling parameter value loaded die casino die (actually, demonstrate rcasino really works , let’s sample vector 100 random die rolls): hypothetical ABC sampling process, demografr sample parameter par (internally automatically) via function sample_prior(): Finally, can verify sampled values really correspond loaded die throws six much often others:","code":"rcasino <- function(n = 1) {   outcomes      <- c(1, 2, 3, 4, 5, 6) # six sides of a die   probabilities <- c(1, 1, 1, 1, 1, 3) # rolling a 6 is 3x more likely!    sample(outcomes, size = n, prob = probabilities, replace = TRUE) } par <- rolls[100] ~ rcasino() samples <- sample_prior(par) samples #> $variable #> [1] \"rolls\" #>  #> $value #>   [1] 6 5 4 6 1 4 6 6 6 6 6 6 2 5 5 5 1 6 2 4 1 6 2 6 3 5 1 6 2 6 5 1 3 4 6 1 1 #>  [38] 4 1 4 3 6 6 6 3 3 4 6 6 3 4 6 3 6 1 6 5 2 6 5 2 3 6 1 2 4 6 6 3 6 6 5 6 6 #>  [75] 6 5 2 4 4 6 5 2 6 6 5 6 6 6 6 2 4 3 4 4 6 6 4 1 6 2 table(samples$value) #>  #>  1  2  3  4  5  6  #> 11 11 10 15 12 41"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"example-analysis","dir":"Articles","previous_headings":"","what":"Example analysis","title":"Parameter grid simulations","text":"demonstrate features demografr grid-based simulation inference, let’s try reproduce result Petr et al. (PNAS 2018). Briefly, paper made attempt explain discrepancies two different ways estimate proportion Neanderthal ancestry Europe tens thousands years. first statistic (dubbed “indirect f4f_4-ratio” statistic) showed following pattern Neanderthal ancestry significantly declining time (figure Fu et al., Nature 2016)  alternative statistic (called “direct f4f_4-ratio” statistic, shown figure solid line contrast “indirect f4f_4-statistic” dashed line) find significant decline shown figure Petr et al. (PNAS 2018).  question , two measures Neanderthal ancestry leading different conclusions? violations assumptions (unaccounted-gene-flow events modern human populations) break one ? way PNAS 2018 study approached problem run many simulation replicates across large parameter grid. required writing custom coalescent simulations, orchestrating running across parameter grid, collecting genotypes simulations produced, computing population genetic statistics (direct indirect f4f_4-ratios)—, couple hundred lines Python, R, bash. vignette shows use demografr perform kind workflows much straightforward reproducible manner, entirely R.","code":""},{"path":[]},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"define-a-slendr-model-function-capturing-the-demographic-history","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"1. Define a slendr model function capturing the demographic history","title":"Parameter grid simulations","text":"standard ABC pipeline using demografr, leverage slendr R package first define demografic model, encoding simple R function. , standard ABC, arguments function correspond model parameters. Note come parameter grid, via sampling priors ABC. example, research question interest involved various gene-flow rates populations model, fix split times NeN_e values interesting important simple inference workflow (ignore Eurasia Africa “backflow” reason): Let’s check model function visualizing (set gene-flow rates arbitrary values, purely visualization test):  model looks OK, next step define summary statistics statistics interested (, just ABC pipeline).","code":"model <- function(rate_ea, rate_aa) {   # create populations   chimp <- population(\"chimp\", time = 7e6,   N = 10000)   anc   <- population(\"anc\",   time = 6e6,   N = 10000, parent = chimp)   nea   <- population(\"nea\",   time = 600e3, N = 2000,  parent = anc)   afr1  <- population(\"afr1\",  time = 600e3, N = 15000, parent = anc)   afr2  <- population(\"afr2\",  time = 150e3, N = 15000, parent = afr1)   eur   <- population(\"eur\",   time = 75e3,  N = 5000,  parent = afr2)    # define gene-flow events   gf <- list(     # back flow from Eurasia into Africa -- one parameter of interest     gene_flow(from = eur, to = afr1, start = 5e3, end = 0, rate = rate_ea),     gene_flow(from = eur, to = afr2, start = 5e3, end = 0, rate = rate_ea),      # gene flow within Africa -- another parameter of interest     gene_flow(from = afr1, to = afr2, start = 50e3, end = 0, rate = rate_aa),     gene_flow(from = afr2, to = afr1, start = 50e3, end = 0, rate = rate_aa),      # Neanderthal introgression (fixed to 3%)     gene_flow(from = nea, to = eur, start = 60e3, end = 50e3, rate = 0.03)   )    # generate a slendr model   model <- compile_model(     populations = list(chimp, anc, nea, afr1, afr2, eur), gene_flow = gf,     generation_time = 30, serialize = FALSE   )    # specify sampling events   samples <- rbind(     # Altai (70 kya) and Vindija (40 kya) Neanderthals     schedule_sampling(model, times = c(70e3, 40e3), list(nea, 1)),     # Europeans from 40 kya to the present     schedule_sampling(model, times = seq(40000, 0, -2000), list(eur, 1)),     # two African populations     schedule_sampling(model, times = 0, list(afr1, 1), list(afr2, 1)),     # Chimpanzee outgroup     schedule_sampling(model, times = 0, list(chimp, 1))   )    return(list(model, samples)) } test_model <- model(rate_ea = 0.42, rate_aa = 0.42)[[1]]  plot_grid(   plot_model(test_model, gene_flow = FALSE),   plot_model(test_model, log = TRUE, gene_flow = TRUE) )"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"define-summary-statistics","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"2. Define summary statistics","title":"Parameter grid simulations","text":"Recall want explore impact modern-human gene flow Neanderthal ancestry inferred using two ways computing : “indirect” “direct” f4f_4-ratio statistics. model samples 21 European individuals across last 40 thousand years, compute f4f_4-ratio statistics individuals sequence. demografr uses R package slendr just encoding demographic models popgen simulations, also tree-sequences computation via interface powerful library tskit. One advantage slendr allows referring simulated samples via “symbolic names”. means , instance, first individual sampled population “eur” named “eur_1”, second named “eur_2”, etc. Therefore, can capture names every European individual vector X running: use vector tree-sequence function slendr/tskit. Specifically, can define “indirect” “direct” f4f_4-ratio statistics way (using equations defined figure ): Exactly ’s case ABC, purposes grid-based simulations define functions used compute summary statistics whose behavior across parameter grid want investigate: looks quite neat tidy, can make sure tree-sequence summary functions really work? need simulated tree-sequence object first! demografr provides easy way get arbitrary tree sequence model function via helper function simulate_model. simples way use like : tiny tree sequence testing, can now check tree-sequence functions work ’re supposed : Excellent, get output tables ts_f4ratio functions ’re supposed (get one estimate 21):","code":"X <- paste0(\"eur_\", 1:21) X #>  [1] \"eur_1\"  \"eur_2\"  \"eur_3\"  \"eur_4\"  \"eur_5\"  \"eur_6\"  \"eur_7\"  \"eur_8\"  #>  [9] \"eur_9\"  \"eur_10\" \"eur_11\" \"eur_12\" \"eur_13\" \"eur_14\" \"eur_15\" \"eur_16\" #> [17] \"eur_17\" \"eur_18\" \"eur_19\" \"eur_20\" \"eur_21\" # compute the \"indirect\" f4-ratio statistic via slendr/tskit function ts_f4ratio, # returning its data frame output as it is indirect <- function(ts) {   X <- paste0(\"eur_\", 1:21)   ts_f4ratio(ts, X = X, A = \"afr1_1\", B = \"afr2_1\", C = \"nea_2\", O = \"chimp_1\") }  # compute the \"direct\" f4-ratio statistic via slendr/tskit function ts_f4ratio, # returning its data frame output as it is direct <- function(ts) {   X <- paste0(\"eur_\", 1:21)   ts_f4ratio(ts, X = X, A = \"nea_2\", B = \"nea_1\", C = \"afr1_1\", O = \"chimp_1\") } # bind both functions in a named list functions <- list(direct = direct, indirect = indirect) # we don't care about the parameter values, as we only want to get a tree sequence # (also, note we did not specify sequence length, recombination rate, etc.) ts <- simulate_model(   model, parameters = list(rate_ea = 0.1, rate_aa = 0.15),   sequence_length = 1e6, recombination_rate = 1e-8, mutation_rate = 1e-8 ) functions$direct(ts) #> # A tibble: 21 × 6 #>    X      A     B     C      O         alpha #>    <chr>  <chr> <chr> <chr>  <chr>     <dbl> #>  1 eur_1  nea_2 nea_1 afr1_1 chimp_1 0.106   #>  2 eur_2  nea_2 nea_1 afr1_1 chimp_1 0.00455 #>  3 eur_3  nea_2 nea_1 afr1_1 chimp_1 0.00455 #>  4 eur_4  nea_2 nea_1 afr1_1 chimp_1 0.0121  #>  5 eur_5  nea_2 nea_1 afr1_1 chimp_1 0.0766  #>  6 eur_6  nea_2 nea_1 afr1_1 chimp_1 0.0842  #>  7 eur_7  nea_2 nea_1 afr1_1 chimp_1 0.0197  #>  8 eur_8  nea_2 nea_1 afr1_1 chimp_1 0.191   #>  9 eur_9  nea_2 nea_1 afr1_1 chimp_1 0.0485  #> 10 eur_10 nea_2 nea_1 afr1_1 chimp_1 0.0106  #> # ℹ 11 more rows functions$indirect(ts) #> # A tibble: 21 × 6 #>    X      A      B      C     O       alpha #>    <chr>  <chr>  <chr>  <chr> <chr>   <dbl> #>  1 eur_1  afr1_1 afr2_1 nea_2 chimp_1 0.704 #>  2 eur_2  afr1_1 afr2_1 nea_2 chimp_1 1.02  #>  3 eur_3  afr1_1 afr2_1 nea_2 chimp_1 0.959 #>  4 eur_4  afr1_1 afr2_1 nea_2 chimp_1 1.06  #>  5 eur_5  afr1_1 afr2_1 nea_2 chimp_1 0.878 #>  6 eur_6  afr1_1 afr2_1 nea_2 chimp_1 0.819 #>  7 eur_7  afr1_1 afr2_1 nea_2 chimp_1 0.920 #>  8 eur_8  afr1_1 afr2_1 nea_2 chimp_1 0.788 #>  9 eur_9  afr1_1 afr2_1 nea_2 chimp_1 0.922 #> 10 eur_10 afr1_1 afr2_1 nea_2 chimp_1 0.884 #> # ℹ 11 more rows functions$direct(ts) %>% nrow #> [1] 21 functions$indirect(ts) %>% nrow #> [1] 21"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"define-a-parameter-grid","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"3. Define a parameter grid","title":"Parameter grid simulations","text":"Finally (yet , analogously equivalent ABC pipeline) define parameters simulate . Specifically, grid simulation, define data frame one column parameter slendr model function (names parameter columns must match model function arguments!). purpose, function crossing tidyr R package particularly helpful, let’s use : way, defined 121 parameter combinations can finally proceed simulation inference.","code":"library(tidyr)  grid <- crossing(   rate_aa = seq(0, 0.25, 0.025),   rate_ea = seq(0, 0.25, 0.025) )  head(grid) #> # A tibble: 6 × 2 #>   rate_aa rate_ea #>     <dbl>   <dbl> #> 1       0   0     #> 2       0   0.025 #> 3       0   0.05  #> 4       0   0.075 #> 5       0   0.1   #> 6       0   0.125"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"perform-grid-based-simulations-compute-summary-statistics-for-each","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"4. Perform grid-based simulations, compute summary statistics for each","title":"Parameter grid simulations","text":"final analogy ABC inference demografr, function simulate_grid() works little similarly simulate_abc() introduced first vignette. fact, function nearly identical interface—plug model function, parameter grid, list summary tree-sequence functions, number simulation replicates perform parameter combination (obvious parameters shown ). First, set automated parallelization scheme using future R package: (See much detail parallelization demografr inference pipelines vignette). total runtime grid simulations 1 hours 8 minutes 8 seconds parallelized across 96 CPUs.","code":"library(future)  # parallelize simulations across all CPUs of the machine plan(multisession, workers = availableCores()) results <- simulate_grid(   model, grid, functions, replicates = 50,   sequence_length = 25e6, mutation_rate = 1e-8, recombination_rate = 1e-8 )"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"examine-results","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"5. Examine results","title":"Parameter grid simulations","text":"function simulate_grid() returns results data frame object following format: first column indicates replicate number, following columns values parameter grid. important last columns, though, named single summary statistics (.e., symbolic names taken named-list summary functions ). conciseness, values summary statistics stored -called “list columns”— replicate parameter combination, columns store summary statistics “nested” data frames. instance, results “direct” f4−ratiof_4-ratio statistic across first three simulation runs. can see list-column \"direct\" contains list data frames, one data frame simulation replicate: List columns efficient concise storing complex data like , order able analyze data stored , need function unnest() tidyverse, “unpacks” list-column stored data frames wider data frame stores actual values given statistic normal numerical column. example: Direct f4-ratio: Indirect f4-ratio: interested behavior trajectories indirect direct estimates Neanderthal ancestry time assuming different values demographic parameters, first create small data frame indicating times sampling simulated European individual. use small data frame join operations purpose plotting :","code":"print(results, n = 10) #> # A tibble: 6,050 × 5 #>      rep rate_aa rate_ea direct            indirect          #>    <int>   <dbl>   <dbl> <list>            <list>            #>  1     1       0   0     <tibble [21 × 6]> <tibble [21 × 6]> #>  2     1       0   0.025 <tibble [21 × 6]> <tibble [21 × 6]> #>  3     1       0   0.05  <tibble [21 × 6]> <tibble [21 × 6]> #>  4     1       0   0.075 <tibble [21 × 6]> <tibble [21 × 6]> #>  5     1       0   0.1   <tibble [21 × 6]> <tibble [21 × 6]> #>  6     1       0   0.125 <tibble [21 × 6]> <tibble [21 × 6]> #>  7     1       0   0.15  <tibble [21 × 6]> <tibble [21 × 6]> #>  8     1       0   0.175 <tibble [21 × 6]> <tibble [21 × 6]> #>  9     1       0   0.2   <tibble [21 × 6]> <tibble [21 × 6]> #> 10     1       0   0.225 <tibble [21 × 6]> <tibble [21 × 6]> #> # ℹ 6,040 more rows results$direct[1:3] #> [[1]] #> # A tibble: 21 × 6 #>    X      A     B     C      O        alpha #>    <chr>  <chr> <chr> <chr>  <chr>    <dbl> #>  1 eur_1  nea_2 nea_1 afr1_1 chimp_1 0.0428 #>  2 eur_2  nea_2 nea_1 afr1_1 chimp_1 0.0699 #>  3 eur_3  nea_2 nea_1 afr1_1 chimp_1 0.0226 #>  4 eur_4  nea_2 nea_1 afr1_1 chimp_1 0.0668 #>  5 eur_5  nea_2 nea_1 afr1_1 chimp_1 0.0442 #>  6 eur_6  nea_2 nea_1 afr1_1 chimp_1 0.0577 #>  7 eur_7  nea_2 nea_1 afr1_1 chimp_1 0.0779 #>  8 eur_8  nea_2 nea_1 afr1_1 chimp_1 0.0578 #>  9 eur_9  nea_2 nea_1 afr1_1 chimp_1 0.0410 #> 10 eur_10 nea_2 nea_1 afr1_1 chimp_1 0.0535 #> # ℹ 11 more rows #>  #> [[2]] #> # A tibble: 21 × 6 #>    X      A     B     C      O         alpha #>    <chr>  <chr> <chr> <chr>  <chr>     <dbl> #>  1 eur_1  nea_2 nea_1 afr1_1 chimp_1 0.00150 #>  2 eur_2  nea_2 nea_1 afr1_1 chimp_1 0.0105  #>  3 eur_3  nea_2 nea_1 afr1_1 chimp_1 0.0151  #>  4 eur_4  nea_2 nea_1 afr1_1 chimp_1 0.0103  #>  5 eur_5  nea_2 nea_1 afr1_1 chimp_1 0.0241  #>  6 eur_6  nea_2 nea_1 afr1_1 chimp_1 0.0141  #>  7 eur_7  nea_2 nea_1 afr1_1 chimp_1 0.0283  #>  8 eur_8  nea_2 nea_1 afr1_1 chimp_1 0.00486 #>  9 eur_9  nea_2 nea_1 afr1_1 chimp_1 0.0258  #> 10 eur_10 nea_2 nea_1 afr1_1 chimp_1 0.00357 #> # ℹ 11 more rows #>  #> [[3]] #> # A tibble: 21 × 6 #>    X      A     B     C      O        alpha #>    <chr>  <chr> <chr> <chr>  <chr>    <dbl> #>  1 eur_1  nea_2 nea_1 afr1_1 chimp_1 0.0489 #>  2 eur_2  nea_2 nea_1 afr1_1 chimp_1 0.0286 #>  3 eur_3  nea_2 nea_1 afr1_1 chimp_1 0.0409 #>  4 eur_4  nea_2 nea_1 afr1_1 chimp_1 0.0169 #>  5 eur_5  nea_2 nea_1 afr1_1 chimp_1 0.0341 #>  6 eur_6  nea_2 nea_1 afr1_1 chimp_1 0.0266 #>  7 eur_7  nea_2 nea_1 afr1_1 chimp_1 0.0381 #>  8 eur_8  nea_2 nea_1 afr1_1 chimp_1 0.0299 #>  9 eur_9  nea_2 nea_1 afr1_1 chimp_1 0.0467 #> 10 eur_10 nea_2 nea_1 afr1_1 chimp_1 0.0380 #> # ℹ 11 more rows results %>% unnest(direct) #> # A tibble: 127,050 × 10 #>      rep rate_aa rate_ea X      A     B     C      O        alpha indirect #>    <int>   <dbl>   <dbl> <chr>  <chr> <chr> <chr>  <chr>    <dbl> <list>   #>  1     1       0       0 eur_1  nea_2 nea_1 afr1_1 chimp_1 0.0428 <tibble> #>  2     1       0       0 eur_2  nea_2 nea_1 afr1_1 chimp_1 0.0699 <tibble> #>  3     1       0       0 eur_3  nea_2 nea_1 afr1_1 chimp_1 0.0226 <tibble> #>  4     1       0       0 eur_4  nea_2 nea_1 afr1_1 chimp_1 0.0668 <tibble> #>  5     1       0       0 eur_5  nea_2 nea_1 afr1_1 chimp_1 0.0442 <tibble> #>  6     1       0       0 eur_6  nea_2 nea_1 afr1_1 chimp_1 0.0577 <tibble> #>  7     1       0       0 eur_7  nea_2 nea_1 afr1_1 chimp_1 0.0779 <tibble> #>  8     1       0       0 eur_8  nea_2 nea_1 afr1_1 chimp_1 0.0578 <tibble> #>  9     1       0       0 eur_9  nea_2 nea_1 afr1_1 chimp_1 0.0410 <tibble> #> 10     1       0       0 eur_10 nea_2 nea_1 afr1_1 chimp_1 0.0535 <tibble> #> # ℹ 127,040 more rows results %>% unnest(indirect) #> # A tibble: 127,050 × 10 #>      rep rate_aa rate_ea direct            X      A      B     C     O     alpha #>    <int>   <dbl>   <dbl> <list>            <chr>  <chr>  <chr> <chr> <chr> <dbl> #>  1     1       0       0 <tibble [21 × 6]> eur_1  afr1_1 afr2… nea_2 chim… 0.958 #>  2     1       0       0 <tibble [21 × 6]> eur_2  afr1_1 afr2… nea_2 chim… 0.949 #>  3     1       0       0 <tibble [21 × 6]> eur_3  afr1_1 afr2… nea_2 chim… 0.995 #>  4     1       0       0 <tibble [21 × 6]> eur_4  afr1_1 afr2… nea_2 chim… 0.966 #>  5     1       0       0 <tibble [21 × 6]> eur_5  afr1_1 afr2… nea_2 chim… 0.968 #>  6     1       0       0 <tibble [21 × 6]> eur_6  afr1_1 afr2… nea_2 chim… 0.916 #>  7     1       0       0 <tibble [21 × 6]> eur_7  afr1_1 afr2… nea_2 chim… 0.885 #>  8     1       0       0 <tibble [21 × 6]> eur_8  afr1_1 afr2… nea_2 chim… 0.948 #>  9     1       0       0 <tibble [21 × 6]> eur_9  afr1_1 afr2… nea_2 chim… 0.984 #> 10     1       0       0 <tibble [21 × 6]> eur_10 afr1_1 afr2… nea_2 chim… 0.971 #> # ℹ 127,040 more rows samples <- tibble(   X = paste0(\"eur_\", 1:21),   time = seq(40000, 0, -2000) )"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"within-african-gene-flow-vs-inference-of-neanderthal-ancestry","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"Within-African gene flow vs inference of Neanderthal ancestry","title":"Parameter grid simulations","text":"Let’s look values indirect direct f4f_4-ratio statistics assuming different values gene flow two African subpopulations:","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"indirect-f_4-ratio","dir":"Articles","previous_headings":"Grid simulation with demografr > Within-African gene flow vs inference of Neanderthal ancestry","what":"Indirect f4f_4-ratio","title":"Parameter grid simulations","text":"","code":"results %>%   unnest(indirect) %>%   filter(rate_ea == 0) %>%          # ignore models with Eurasian -> African gene flow   inner_join(samples, by = \"X\") %>% # join the samples table to add time information   ggplot(aes(time, 1 - alpha, color = rate_aa, group = rate_aa)) +     geom_line(stat = \"smooth\", se = FALSE) +     geom_hline(yintercept = 0.03, color = \"red\", linetype = \"dashed\") +     geom_hline(yintercept = 0, color = \"black\", linetype = \"dotted\") +     labs(x = \"years before present\", y = \"Neanderthal ancestry proportion\") +     xlim(40000, 0) +     coord_cartesian(y = c(0, 0.1)) +     ggtitle(\"The effect of within-Africa gene flow (afr1 <-> afr2) on 'indirect f4-ratio'\",             \"Red line indicates the true Neanderthal ancestry proportion\") #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"direct-f_4-ratio","dir":"Articles","previous_headings":"Grid simulation with demografr > Within-African gene flow vs inference of Neanderthal ancestry","what":"Direct f4f_4-ratio","title":"Parameter grid simulations","text":"can see increasing rates gene flow within Africa shifts apparent Neanderthal ancestry proportions inferred using “indirect” f4f_4-ratio increasingly upwards (compare estimated trajectories true proportion shown dashed line). However, “direct” f4f_4-ratio remains stable, relatively closer true admixture proportion indicated dashed line.","code":"results %>%   unnest(direct) %>%   filter(rate_ea == 0) %>%   inner_join(samples, by = \"X\") %>%   ggplot(aes(time, alpha, color = rate_aa, group = rate_aa)) +     geom_line(stat = \"smooth\", se = FALSE) +     geom_hline(yintercept = 0.03, color = \"red\", linetype = \"dashed\") +     geom_hline(yintercept = 0, color = \"black\", linetype = \"dotted\") +     labs(x = \"years before present\", y = \"Neanderthal ancestry proportion\") +     xlim(40000, 0) +     coord_cartesian(y = c(0, 0.1)) +     ggtitle(\"The effect of within-Africa gene flow (afr1 <-> afr2) on 'direct f4-ratio'\",             \"Dashed line indicates the true Neanderthal ancestry proportion\") #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"eurasia---africa-gene-flow-vs-inference-of-neanderthal-ancestry","dir":"Articles","previous_headings":"Grid simulation with demografr","what":"Eurasia -> Africa gene flow vs inference of Neanderthal ancestry","title":"Parameter grid simulations","text":"Now let’s investigate behavior statistic models ’s proportion backflow Eurasia back Africa:   can see gene flow Eurasia back Africa creates artificial decline Neanderthal ancestry measured via “indirect” f4f_4-ratio statistic! However, “direct” f4f_4-ratio remains stable , , relatively close true admixture proportion.","code":"results %>%   unnest(indirect) %>%   filter(rate_aa == 0.2) %>%   inner_join(samples, by = \"X\") %>%   ggplot(aes(time, 1 - alpha, color = rate_ea, group = rate_ea)) +     geom_line(stat = \"smooth\", se = FALSE) +     geom_hline(yintercept = 0.03, color = \"red\", linetype = \"dashed\") +     geom_hline(yintercept = 0, color = \"black\", linetype = \"dotted\") +     labs(x = \"years before present\", y = \"Neanderthal ancestry proportion\") +     xlim(40000, 0) +     coord_cartesian(y = c(0, 0.1)) +     ggtitle(\"The effect of Eurasia -> Africa gene flow on 'indirect f4-ratio'\",             \"Dashed line indicates the true Neanderthal ancestry proportion\") #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")' results %>%   unnest(direct) %>%   filter(rate_aa == 0.2) %>%   inner_join(samples, by = \"X\") %>%   ggplot(aes(time, alpha, color = rate_ea, group = rate_ea)) +     geom_line(stat = \"smooth\", se = FALSE) +     geom_hline(yintercept = 0.03, color = \"red\", linetype = \"dashed\") +     geom_hline(yintercept = 0, color = \"black\", linetype = \"dotted\") +     labs(x = \"years before present\", y = \"Neanderthal ancestry proportion\") +     xlim(40000, 0) +     coord_cartesian(y = c(0, 0.1)) +     ggtitle(\"The effect of Eurasia -> Africa gene flow on 'direct f4-ratio'\",             \"Dashed line indicates the true Neanderthal ancestry proportion\") #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"},{"path":"https://bodkan.net/demografr/articles/vignette-03-grids.html","id":"comparison-with-the-result-by-petr-et-al--pnas-2018","dir":"Articles","previous_headings":"","what":"Comparison with the result by Petr et al. (PNAS 2018)","title":"Parameter grid simulations","text":"can see, simple simulation-based investigation described vignette (total just couple dozen lines easy--read R code) can qualitatively replicate much original result ppaerpaper (required couple hundreds lines Python / shell / R scripts):","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-04-parallelization.html","id":"implicit-parallelization-via-future","dir":"Articles","previous_headings":"","what":"1. Implicit parallelization via future","title":"Parallelization options","text":"simplest way parallelize demografr workflow via R package future. magic future lies ability set parallelized schemes arbitrary topologies automatic scheduling jobs across given number CPUs distributed even across several remote compute servers. Going detail setting future-based parallelization far scope simple vignette (demografr’s documentation general). Luckily, future parallelization set , doesn’t matter whether computation done demografr anything else, future architecture completely general. order use future effectively, study documentation tutorials (good start vignette ), brief introduction focused parallelizing toy demografr analysis set :","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-04-parallelization.html","id":"sequential-run","dir":"Articles","previous_headings":"1. Implicit parallelization via future","what":"Sequential run","title":"Parallelization options","text":"default, run simulate_grid(), simulations run sequentially: total runtime grid simulations 0 hours 0 minutes 47 seconds parallelized across 10 CPUs.","code":"data <- simulate_grid(model, grid, functions, replicates = 10,                       sequence_length = 10000, recombination_rate = 1e-8)  data #> # A tibble: 90 × 4 #>      rep Ne_p1 Ne_p2 diversity        #>    <int> <dbl> <dbl> <list>           #>  1     1    10    10 <tibble [2 × 2]> #>  2     1    10   100 <tibble [2 × 2]> #>  3     1    10  1000 <tibble [2 × 2]> #>  4     1   100    10 <tibble [2 × 2]> #>  5     1   100   100 <tibble [2 × 2]> #>  6     1   100  1000 <tibble [2 × 2]> #>  7     1  1000    10 <tibble [2 × 2]> #>  8     1  1000   100 <tibble [2 × 2]> #>  9     1  1000  1000 <tibble [2 × 2]> #> 10     2    10    10 <tibble [2 × 2]> #> # ℹ 80 more rows"},{"path":"https://bodkan.net/demografr/articles/vignette-04-parallelization.html","id":"parallelization-across-cpus-of-one-machine","dir":"Articles","previous_headings":"1. Implicit parallelization via future","what":"Parallelization across CPUs of one machine","title":"Parallelization options","text":"order distribute simulations across () available CPU cores machine, need put following bit R code call simulate_grid(). instance, personal laptop 10 CPUs, can run grid simulations using available CPUs like . First setup future: can run simulations without anything else! last point important: demografr can automatically leverage whatever parallelization scheme set via future’s function plan(). total runtime grid simulations 0 hours 0 minutes 21 seconds parallelized across 10 CPUs. Notice speed even trivial simulation pipeline!","code":"library(future) plan(multisession, workers = 10) # use 10 CPUs data <- simulate_grid(model, grid, functions, replicates = 10,                       sequence_length = 100000, recombination_rate = 1e-8)  data #> # A tibble: 90 × 4 #>      rep Ne_p1 Ne_p2 diversity        #>    <int> <dbl> <dbl> <list>           #>  1     1    10    10 <tibble [2 × 2]> #>  2     1    10   100 <tibble [2 × 2]> #>  3     1    10  1000 <tibble [2 × 2]> #>  4     1   100    10 <tibble [2 × 2]> #>  5     1   100   100 <tibble [2 × 2]> #>  6     1   100  1000 <tibble [2 × 2]> #>  7     1  1000    10 <tibble [2 × 2]> #>  8     1  1000   100 <tibble [2 × 2]> #>  9     1  1000  1000 <tibble [2 × 2]> #> 10     2    10    10 <tibble [2 × 2]> #> # ℹ 80 more rows"},{"path":"https://bodkan.net/demografr/articles/vignette-04-parallelization.html","id":"parallelization-across-cpus-of-multiple-machines","dir":"Articles","previous_headings":"1. Implicit parallelization via future","what":"Parallelization across CPUs of multiple machines","title":"Parallelization options","text":"read documentation future package (really ), discover many options parallelization giving near limitless options scheduling parallel simulations. instance, imagine access remote machines server01, server02, server03, available R well demografr slendr R packages, set slendr environments. words, can start R interpreter machines eventually call: , can distribute simulate_grid() run (also simulate_abc(), course!) simply adjusting plan() setup like : won’t running example practice “server01”, etc., obviously don’t exist, hopefully get idea. short, future R package (’s support provided demografr) makes easy set arbitrary parallelization schemes without additional work beyond setting parallelization plan().","code":"library(demografr) library(slendr) init_env() #> The interface to all required Python modules has been activated. hostnames <- c(\"server01\", \"server02\") plan(multisession, workers = hostnames)"},{"path":"https://bodkan.net/demografr/articles/vignette-04-parallelization.html","id":"for-completeness","dir":"Articles","previous_headings":"1. Implicit parallelization via future","what":"For completeness","title":"Parallelization options","text":"default, don’t set plan() , simulation runs demografr run sequential manner, default mode operation future R package following plan: just completeness. ’s something makes much sense practice, perhaps beyond debugging parallelization issues.","code":"plan(sequential)"},{"path":"https://bodkan.net/demografr/articles/vignette-04-parallelization.html","id":"manual-parallelization","dir":"Articles","previous_headings":"","what":"2. “Manual” parallelization","title":"Parallelization options","text":"personal experience, can bit hassle distribute jobs across different machines, despite conveniences future R package. ’re problems, first highly encourage read basic overview vignette look troubleshooting advice Google. Still, demografr provides rudimentary support “manual” paralelization across multiple machines (machines parallelizing multiple CPUs), followed merging simulation runs single data set. demonstrate , let’s pretend ran five simulation grid runs across two different computers like (originally interested distributing 10 replicates, ’ll run two times five replicates individually): , collected individual .rds files single computer remote machines (perhaps using something like scp unix command), can use another demografr function combine_data() merge individual runs single result: combination parameters ran five replicates across “two different machines”, totaling 9 x 5 x 2 = 90 simulations, get number rows merged data frame: One thing note simulate_grid() well simulate_abc() really save standard RDS files one normally using function saveRDS() (fact, use function internally). additional benefit using approach combined combine_data() functions provide additional sanity checks making sure simulation data sets merged consistent (coming model function, priors summary statistics, etc.). completeness, combine_data() accepts file paths individual function arguments also file names vectors, well individual data frame objects generated simulate_grid() simulate_abc(). words, following approaches result combined data set: Merging data serialized data files: Merging data objects directly: combine_data() approaches give result:","code":"library(future) plan(multisession, workers = 5) run1_file <- tempfile(fileext = \".rds\") run2_file <- tempfile(fileext = \".rds\")  # on machine #1 simulate_grid(model, grid, functions, replicates = 5,               sequence_length = 100000, recombination_rate = 1e-8, file = run1_file)  # on machine #2 simulate_grid(model, grid, functions, replicates = 5,               sequence_length = 100000, recombination_rate = 1e-8, file = run2_file) data <- combine_data(run1_file, run2_file)  data #> # A tibble: 90 × 4 #>      rep Ne_p1 Ne_p2 diversity        #>    <int> <dbl> <dbl> <list>           #>  1     1    10    10 <tibble [2 × 2]> #>  2     1    10   100 <tibble [2 × 2]> #>  3     1    10  1000 <tibble [2 × 2]> #>  4     1   100    10 <tibble [2 × 2]> #>  5     1   100   100 <tibble [2 × 2]> #>  6     1   100  1000 <tibble [2 × 2]> #>  7     1  1000    10 <tibble [2 × 2]> #>  8     1  1000   100 <tibble [2 × 2]> #>  9     1  1000  1000 <tibble [2 × 2]> #> 10     2    10    10 <tibble [2 × 2]> #> # ℹ 80 more rows nrow(data) #> [1] 90 combined1 <- combine_data(run1_file, run2_file) combined2 <- combine_data(list(run1_file, run2_file)) run1 <- simulate_grid(model, grid, functions, replicates = 5,                       sequence_length = 100000, recombination_rate = 1e-8) run2 <- simulate_grid(model, grid, functions, replicates = 5,                       sequence_length = 100000, recombination_rate = 1e-8)  combined3 <- combine_data(run1, run2) combined4 <- combine_data(list(run1, run2)) all.equal(combined1, combined2) #> [1] TRUE all.equal(combined3, combined4) #> [1] TRUE all.equal(combined2, combined3) #> [1] TRUE"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"toy-inference-problem","dir":"Articles","previous_headings":"","what":"Toy inference problem","title":"Custom inference using SLiM or Python","text":"Suppose intent use ABC infer NeN_e constant-sized population given observed following value nucleotide diversity: want infer posterior distribution NeN_e. vignette, ’re going show accomplish first via normal slendr interface (shown ) using simple SLiM Python script. later section, ’re also going use example demonstrate compute population genetic summary statistic (like nucleotide diversity) using external software. acknowledge completely trivial example, really worth spending much effort ABC . example chosen runs fast demonstrates features demografr use regardless complexity model.","code":"observed_diversity #> # A tibble: 1 × 2 #>   set   diversity #>   <chr>     <dbl> #> 1 pop   0.0000394"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"using-custom-scripts-as-simulation-engines","dir":"Articles","previous_headings":"","what":"Using custom scripts as simulation engines","title":"Custom inference using SLiM or Python","text":"order able use custom SLiM msprime script demografr, script must conform couple rules:","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"it-must-be-runnable-on-the-command-line-as-any-other-command-line-script","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"1. It must be runnable on the command-line as any other command-line script","title":"Custom inference using SLiM or Python","text":"msprime script, means something like python <script>.py <command-line arguments>. SLiM script, means something like slim <command-line arguments> <script>.slim.","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"it-must-accept---path-argument-pointing-to-a-directory-where-it-will-save-output-files","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"2. It must accept --path argument pointing to a directory where it will save output files","title":"Custom inference using SLiM or Python","text":"analogous path = argument slendr functions slim() msprime(). msprime script, parameter can specified via Python built-module argparse, provided command-line --path <path directory>. script , use argparse module thus values provided arguments (instance) args object, can refer arguments args.path, etc. Given ’re reading , assume know information means, ’s link relevant section Python documentation completeness. SLiM script, parameter can specified via SLiM’s standard way supplying command-line arguments -d \"path='<path directory>'\". Importantly, note SLiM’s format specifying string arguments path argument. need detail, see Section 20.2 SLiM manual. script , can refer argument via constant path.","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"all-model-parameters-must-be-provided-as-additional-command-line-arguments","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"3. All model parameters must be provided as additional command-line arguments","title":"Custom inference using SLiM or Python","text":"can refer script mandatory arguments described previous section. useful check see whether script make valid engine demografr inference pipeline run manually command line like : , want run SLiM-powered ABC, like : , look directory see desired files produced simulation script, ’re good go! going see actually read back simulation results disk use computing summary statistics. now, just note can name files produced simulation script however ’d like can many ’d like, long one directory given path.","code":"python \\   <path to your Python script>                   \\   --path <path to a directory> \\   <... your model parameters ...> slim \\   -d \"path='<path to a directory>'\" \\   <... your model parameters ...>"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"example-pure-slim-and-msprime-script","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"Example pure SLiM and msprime script","title":"Custom inference using SLiM or Python","text":"demonstrate requirements 1-3 practice, let’s run ABC inference using example msprime script SLiM script simulation engines. Imagine following two scripts want use simulation engines instead slendr’s functions slim() msprime(). scripts one model parameter, NeN_e single modeled population. parameters mandatory, just discussed previous section.","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"slim-script","dir":"Articles","previous_headings":"Using custom scripts as simulation engines > Example pure SLiM and msprime script","what":"SLiM script","title":"Custom inference using SLiM or Python","text":"","code":"slim_script <- system.file(\"examples/custom.slim\", package = \"demografr\") initialize() {   initializeTreeSeq();   initializeMutationRate(1e-8);   initializeMutationType(\"m1\", 0.5, \"f\", 0.0);   initializeGenomicElementType(\"g1\", m1, 1.0);   initializeGenomicElement(g1, 0, 1e6 - 1);   initializeRecombinationRate(1e-8); }  1 early() {   sim.addSubpop(\"p0\", asInteger(Ne)); }  10000 late() {   ts_path = path + \"/\" + \"result.trees\";   sim.treeSeqOutput(ts_path); }"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"python-script","dir":"Articles","previous_headings":"Using custom scripts as simulation engines > Example pure SLiM and msprime script","what":"Python script","title":"Custom inference using SLiM or Python","text":"Note Python script specifies model parameters (just NeN_e) mandatory arguments via command-line interface provided Python module argparse. SLiM script, hand, uses SLiM’s features command-line specification parameters simply refers parameter symbolic name. setup necessary. Please also note given can discrepancies values arguments SLiM Python methods (addSubPop SLiM expects integer value population size, samples argument msprime.sim_ancestry), values parameters sampled priors demografr (.e., NeN_e often floating-point value sampling continuous prior), might perform explicit type conversion custom scripts (sim.addSubPop(\"p0\", asInteger(Ne) ).","code":"python_script <- system.file(\"examples/custom.py\", package = \"demografr\") import argparse  import msprime  parser = argparse.ArgumentParser()  # mandatory command-line argument parser.add_argument(\"--path\", type=str, required=True)  # model parameters parser.add_argument(\"--Ne\", type=float, required=True)  args = parser.parse_args()  ts = msprime.sim_ancestry(   samples=round(args.Ne),   population_size=args.Ne,   sequence_length=1e6,   recombination_rate=1e-8, )  ts = msprime.sim_mutations(ts, 1e-8)  ts.dump(args.path + \"/\" + \"result.trees\")"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"abc-inference-using-custom-msprime-script","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"ABC inference using custom msprime script","title":"Custom inference using SLiM or Python","text":"Apart user-defined simulation SLiM msprime scripts, components toy inference remains —need define observed statistics, tree-sequence summary functions, priors. don’t need model function—served custom script. demografr pipeline components (won’t discussing ’s extensively taken care elsewhere demografr’s documentation vignettes): (Note simulated tree sequences won’t coming slendr metadata, refer individuals’ chromosomes using numerical indices rather slendr symbolic names like vignettes.)","code":"# a single prior parameter priors <- list(Ne ~ runif(100, 5000))  # a single observed statistic observed <- list(diversity = observed_diversity)  # compute diversity using 100 chromosomes compute_diversity_ts <- function(ts) {   samples <- ts$samples()   ts_diversity(ts, list(pop = sample(samples, 100))) } functions <- list(diversity = compute_diversity_ts)  # data-generating functions for computing summary statistics gens <- list(   ts = function(path) ts_read(file.path(path, \"result.trees\")) )"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"simulating-a-testing-tree-sequence","dir":"Articles","previous_headings":"Using custom scripts as simulation engines > ABC inference using custom msprime script","what":"Simulating a testing tree sequence","title":"Custom inference using SLiM or Python","text":"explained elsewhere, useful function developing inference pipelines using demografr function simulate_model(), normally accepts slendr model generating function model parameters (either given priors list named values), simulates tree-sequence object. function (demografr function operating models) accepts custom-defined simulation scripts place standard slendr models. instance, can simulate couple Mb testing sequence msprime script like : Now can finally test toy tree-sequence summary function, verifying can indeed compute summary statistic want : function works expected—single population want compute nucleotide diversity whole population, exactly get. Note also able use dedicated function , called summarise_data(), takes product simulation (tree sequence /path directory simulation results), apply summary functions data:","code":"model_run <- simulate_model(python_script, parameters = list(Ne = 123), format = \"files\", data = gens) functions$diversity(model_run$ts) #> # A tibble: 1 × 2 #>   set    diversity #>   <chr>      <dbl> #> 1 pop   0.00000359 #> # A tibble: 1 × 2 #>   set    diversity #>   <chr>      <dbl> #> 1 pop   0.00000502 #> $diversity #> # A tibble: 1 × 2 #>   set    diversity #>   <chr>      <dbl> #> 1 pop   0.00000502 summarise_data(model_run, functions) #> $diversity #> # A tibble: 1 × 2 #>   set    diversity #>   <chr>      <dbl> #> 1 pop   0.00000375"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"abc-inference","dir":"Articles","previous_headings":"Using custom scripts as simulation engines > ABC inference using custom msprime script","what":"ABC inference","title":"Custom inference using SLiM or Python","text":"components pipeline set , , validate everything proceed (potentially costly) simulations. remainder vignette ’ll continue Python msprime custom script order save computational time. said, ’s important realize use sort workflow kind SLiM script, including elaborate spatial simulations, non-WF models, kinds phenotypic simulations ! Although primarily designed work slendr, demografr package intends fully support kind SLiM msprime simulation. something doesn’t work, consider demografr bug! Let’s first validate components pipeline: Looking good! Now let’s first run ABC simulations. , note use Python script normally provide slendr model function place model argument: total runtime ABC simulations 0 hours 29 minutes 36 seconds parallelized across 96 CPUs. simulations finished, can perform inference posterior distribution single parameter model, NeN_e: done , can look summary statistics posterior distribution also plot results (’re skipping diagnostics posterior predictive checks can read ). observed diversity based simulated data known model, ’ll indicate true “hidden” NeN_e value vertical line.","code":"validate_abc(python_script, priors, functions, observed, data = gens, format = \"files\") #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne ✅ #> --------------------------------------------------------------------- #> The model is a custom user-defined msprime script #> --------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Validating custom data-generating functions...  ✅ #> --------------------------------------------------------------------- #> Generating data from simulation results: #>   - ts (type slendr_ts) ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup! library(future) plan(multisession, workers = availableCores()) # parallelize across all CPUs  data <- simulate_abc(   model = python_script, priors, functions, observed, iterations = 10000,   data = gens, format = \"files\" ) abc <- run_abc(data, tol = 0.01, method = \"neuralnet\") extract_summary(abc) #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #>                               Ne #> Min.:                   648.0043 #> Weighted 2.5 % Perc.:   683.6240 #> Weighted Median:       1005.4589 #> Weighted Mean:         1044.8909 #> Weighted Mode:          997.3463 #> Weighted 97.5 % Perc.: 1521.7129 #> Max.:                  1555.8246 library(ggplot2)  plot_posterior(abc) +   geom_vline(xintercept = 1000, linetype = \"dashed\") +   coord_cartesian(xlim = c(100, 5000))"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"using-external-programs-to-compute-summary-statistics","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"Using external programs to compute summary statistics","title":"Custom inference using SLiM or Python","text":"Now let’s move things one step forward. either don’t find slendr’s tree-sequence interface tskit sufficient want compute summary statistics simulated data using external software, like PLINK EIGENSTRAT? keep things easy possible (avoid dragging multiple software dependencies), let’s say program vcfpi, run following way: can find /private/var/folders/h2/qs0z_44x2vn2sskqc0cct7540000gn/T/Rtmpf8vkdW/temp_libpathcdc6259afa7d/demografr/examples/vcfpi) run terminal. program takes VCF file computes nucleotide diversity across individuals VCF file. simplicity, produces table results exactly format observed_diversity data frame . particular example, want replace computation statistics performed R function compute_diversity previous section (also produces data frame) product external software vcfpi. (provide vcfpi program example script, course program imagine.) First, definitions priors observed statistics change: change simulated summary statistics definition. number ways go (show others ), given vcfpi command-line program, use function ’s one last thing need – summary function compute_diversity operate tree-sequence file time. Instead, vcfpi requires VCF file input. , simulation model python_script still creates tree-sequence file, need create VCF able compute nucleotide diversity. (course, modify simulation model script produce VCF easily, sake making example bit educational, let’s make job little bit harder). Whenever need run simulation summary statistic different form data tree-sequence, can customize data-generating function(s). first example, provide function creates ts object path directory result files. example, let’s push one step create VCF file. (, ’ve just easily create VCF file simulation script, bear !) look result, can see longer contains ts tree-sequence object path VCF file! Let’s test summary function VCF: , convenience, can using general function summarise_data(): Now let’s validate customized setup unleash full scale ABC simulations problem! total runtime ABC simulations 0 hours 33 minutes 25 seconds parallelized across 96 CPUs. simulations finished, can perform inference posterior distribution single parameter model, NeN_e:","code":"./vcfpi --vcf <path to a VCF> --tsv <path to a TSV table> # a single prior parameter priors <- list(Ne ~ runif(100, 5000))  # a single observed statistic observed <- list(diversity = observed_diversity) compute_pi_vcf <- function(vcf) {   # path to the output summary statistic file   tsv <- tempfile()    # path to the example command-line utility (in this example we use a built-in toy program   # called `vcfpi`, but this could be a path to any other program of your choosing, of course)   program <- system.file(\"examples/vcfpi\", package = \"demografr\")    # execute the program on the command line using appropriate arguments   system2(program, args = c(\"--vcf\", vcf, \"--tsv\", tsv))    # read the computed table with computed nucleotide diversity   # (for simplicity, our example vcfpi program creates an output TSV   # file already in the necessary format but any required reformatting   # changes could easily happen at this stage)   read.table(tsv, header = TRUE) }  functions <- list(diversity = compute_pi_vcf) gens <- list(   vcf = function(path) {     # read the simulated tree sequence from a given path and subset it     # (same code as previously, where we worked exclusively on tree sequences)     ts_path <- file.path(path, \"result.trees\")     ts <- ts_read(ts_path) %>% ts_simplify(simplify_to = seq(0, 99))      # export genotypes from the tree sequence to a VCF (in the same directory)     vcf_path <- file.path(path, \"genotypes.vcf.gz\")     ts_vcf(ts, vcf_path)      # return the path to the VCF for use in computing summary statistics     return(vcf_path)   } ) model_run <- simulate_model(python_script, parameters = list(Ne = 123), format = \"files\", data = gens) model_run #> $vcf #> [1] \"/private/var/folders/h2/qs0z_44x2vn2sskqc0cct7540000gn/T/RtmpNYza4udemografr_1823336464/genotypes.vcf.gz\" functions$diversity(model_run$vcf) #>   set    diversity #> 1 pop 5.164421e-06 summarise_data(model_run, functions) #> $diversity #>   set    diversity #> 1 pop 5.164421e-06 validate_abc(python_script, priors, functions, observed, data = gens, format = \"files\") #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne ✅ #> --------------------------------------------------------------------- #> The model is a custom user-defined msprime script #> --------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Validating custom data-generating functions...  ✅ #> --------------------------------------------------------------------- #> Generating data from simulation results: #>   - vcf (type character) ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup! library(future) plan(multisession, workers = availableCores()) # parallelize across all CPUs  data <- simulate_abc(   model = python_script, priors, functions, observed, iterations = 10000,   data = gens, format = \"files\" ) abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\") extract_summary(abc) #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #>                               Ne #> Min.:                   641.4341 #> Weighted 2.5 % Perc.:   701.8172 #> Weighted Median:        989.0880 #> Weighted Mean:         1026.1556 #> Weighted Mode:          919.2565 #> Weighted 97.5 % Perc.: 1495.9363 #> Max.:                  1566.3955 library(ggplot2)  plot_posterior(abc) +   geom_vline(xintercept = 1000, linetype = \"dashed\") +   coord_cartesian(xlim = c(100, 5000))"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"another-means-of-computing-simulated-summary-statistics","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"Another means of computing simulated summary statistics","title":"Custom inference using SLiM or Python","text":"Let’s look yet another variation . want compute summary statistics R different source genotype data (tree-sequence object memory also VCF file stored disk)? instance, want compute summary statistics simple data frame genotypes (0 – ancestral state, 1 – derived state). can modify pipeline following way. First, need define summary statistic function operate data frame, say called gt. also need data-generating function, create table genotypes standard simulated output: ’s ! Let’s check whole setup works correctly. look result, can see longer contains ts tree-sequence object simple table genotypes created via slendr function ts_genotypes() (see data generating function just ). Let’s test summary function output single testing simulation run: Let’s also validate customized setup unleash full scale ABC simulations problem! total runtime ABC simulations 0 hours 25 minutes 38 seconds parallelized across 96 CPUs. simulations finished, can perform inference posterior distribution single parameter model, NeN_e:","code":"compute_diversity <- function(gt) {   # generate a list of all pairs of chromosomes   pairs <- combn(names(gt[, -1]), 2, simplify = FALSE)    # count the number of nucleotide differences for each pair   diffs <- sapply(pairs, function(pair) sum(gt[[pair[1]]] != gt[[pair[2]]]))      # the mean is the nucleotide diversity of the sample of chromosomes   pi <- mean(diffs) / 1e6    data.frame(set = \"pop\", diversity = pi) }  functions <- list(diversity = compute_diversity) gens <- list(   gt = function(path) {     # read the simulated tree sequence from a given path and subset it     ts_path <- file.path(path, \"result.trees\")     ts <- ts_read(ts_path) %>% ts_simplify(simplify_to = seq(0, 99))     # suppress warnings due to multiallelic sites     suppressWarnings(ts_genotypes(ts))   } ) model_run <- simulate_model(python_script, parameters = list(Ne = 123), format = \"files\", data = gens) model_run #> $gt #> # A tibble: 25 × 101 #>       pos pop_0_0_chr1 pop_0_0_chr2 pop_0_1_chr1 pop_0_1_chr2 pop_0_2_chr1 #>     <int>        <int>        <int>        <int>        <int>        <int> #>  1  13713            0            0            0            0            0 #>  2  34727            0            0            0            0            0 #>  3 115420            0            0            0            0            0 #>  4 121796            0            0            0            0            0 #>  5 129117            0            0            0            0            0 #>  6 141228            0            0            0            0            0 #>  7 204252            0            0            0            0            0 #>  8 290445            1            1            1            1            0 #>  9 310406            0            0            0            0            1 #> 10 341158            0            0            0            0            0 #> # ℹ 15 more rows #> # ℹ 95 more variables: pop_0_2_chr2 <int>, pop_0_3_chr1 <int>, #> #   pop_0_3_chr2 <int>, pop_0_4_chr1 <int>, pop_0_4_chr2 <int>, #> #   pop_0_5_chr1 <int>, pop_0_5_chr2 <int>, pop_0_6_chr1 <int>, #> #   pop_0_6_chr2 <int>, pop_0_7_chr1 <int>, pop_0_7_chr2 <int>, #> #   pop_0_8_chr1 <int>, pop_0_8_chr2 <int>, pop_0_9_chr1 <int>, #> #   pop_0_9_chr2 <int>, pop_0_10_chr1 <int>, pop_0_10_chr2 <int>, … summarise_data(model_run, functions) #> $diversity #>   set   diversity #> 1 pop 4.16202e-06 validate_abc(python_script, priors, functions, observed, data = gens, format = \"files\") #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne ✅ #> --------------------------------------------------------------------- #> The model is a custom user-defined msprime script #> --------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Validating custom data-generating functions...  ✅ #> --------------------------------------------------------------------- #> Generating data from simulation results: #>   - gt (type tbl_df) ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup! library(future) plan(multisession, workers = availableCores())  data <- simulate_abc(   model = python_script, priors, functions, observed, iterations = 10000,   data = gens, format = \"files\" ) abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\") extract_summary(abc) #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #>                               Ne #> Min.:                   593.7036 #> Weighted 2.5 % Perc.:   620.6549 #> Weighted Median:       1013.2286 #> Weighted Mean:         1008.2233 #> Weighted Mode:         1029.4001 #> Weighted 97.5 % Perc.: 1436.4719 #> Max.:                  1584.7489 library(ggplot2)  plot_posterior(abc) +   geom_vline(xintercept = 1000, linetype = \"dashed\") +   coord_cartesian(xlim = c(100, 5000))"},{"path":"https://bodkan.net/demografr/articles/vignette-05-custom.html","id":"computing-summary-statistics-with-python","dir":"Articles","previous_headings":"Using custom scripts as simulation engines","what":"Computing summary statistics with Python","title":"Custom inference using SLiM or Python","text":"last example customization demografr inference pipeline, let’s consider scenario tree-sequence functionality available slendr isn’t sufficient, need compute summary statistics simulated tree-sequence using pure Python tskit module directly. customization examples , easy . First, just change things , let’s say want use normal slendr model function scaffold model inference, simulate tree sequence standard slendr / demografr functionality (.e, via external Python script examples ), customize summary statistic computation nucleotide diversity. use prior observed statistic : look result, can see longer contains ts tree-sequence object simple table genotypes created via slendr function ts_genotypes() (see data generating function just ). Let’s test summary function output single testing simulation run: Let’s also validate customized setup unleash full scale ABC simulations problem! total runtime ABC simulations 0 hours 17 minutes 22 seconds parallelized across 96 CPUs. simulations finished, can perform inference posterior distribution single parameter model, NeN_e:","code":"model <- function(Ne) {   # this will be a single-population coalescent model, so the time of   # the appearance of the population is arbitrary -- let's say we   # want the model to start at 1000 generations ago, just to pick an   # arbitrary point in time   pop <- population(\"pop\", N = Ne, time = 1000)   model <- compile_model(     pop, generation_time = 1,     direction = \"backward\",     serialize = FALSE   )   schedule <- schedule_sampling(model, times = 0, list(pop, 50))   return(list(model, schedule)) } observed_diversity <- readRDS(get_cache(\"examples/custom_diversity.rds\"))  priors <- list(Ne ~ runif(100, 5000))  observed <- list(diversity = observed_diversity) compute_diversity <- function(ts) {   reticulate::py_run_string(r\"( def compute_diversity(ts):     diffs = []      for i in range(ts.num_samples - 1):         for j in range(i + 1, ts.num_samples):             diffs.append(ts.divergence(sample_sets=[[i], [j]], mode=\"site\"))      pi = sum(diffs) / len(diffs)      return pd.DataFrame({\"set\": [\"pop\"], \"diversity\": [pi]}) )\"   )   reticulate::py$compute_diversity(ts) }  functions <- list(diversity = compute_diversity) model_run <- simulate_model(model, parameters = priors, sequence_length = 1e6, recombination_rate = 1e-8) model_run #> ╔═══════════════════════════╗ #> ║TreeSequence               ║ #> ╠═══════════════╤═══════════╣ #> ║Trees          │        679║ #> ╟───────────────┼───────────╢ #> ║Sequence Length│  1,000,000║ #> ╟───────────────┼───────────╢ #> ║Time Units     │generations║ #> ╟───────────────┼───────────╢ #> ║Sample Nodes   │        100║ #> ╟───────────────┼───────────╢ #> ║Total Size     │  123.5 KiB║ #> ╚═══════════════╧═══════════╝ #> ╔═══════════╤═════╤═════════╤════════════╗ #> ║Table      │Rows │Size     │Has Metadata║ #> ╠═══════════╪═════╪═════════╪════════════╣ #> ║Edges      │2,579│ 80.6 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Individuals│   50│  1.4 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Migrations │    0│  8 Bytes│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Mutations  │    0│ 16 Bytes│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Nodes      │  691│ 18.9 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Populations│    1│222 Bytes│         Yes║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Provenances│    1│  1.4 KiB│          No║ #> ╟───────────┼─────┼─────────┼────────────╢ #> ║Sites      │    0│ 16 Bytes│          No║ #> ╚═══════════╧═════╧═════════╧════════════╝ summarise_data(model_run, functions) #> $diversity #>   set diversity #> 1 pop         0 validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 0) #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne ✅ #> --------------------------------------------------------------------- #> The model is a slendr function #> --------------------------------------------------------------------- #> Checking the return statement of the model function... ✅ #> --------------------------------------------------------------------- #> Checking the presence of required model function arguments...--------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup! library(future) plan(multisession, workers = availableCores())  data <- simulate_abc(   model, priors, functions, observed, iterations = 10000,   sequence_length = 1e6, recombination_rate = 1e-8, mutation_rate = 1e-8 ) abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\") extract_summary(abc) #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #>                               Ne #> Min.:                   565.2685 #> Weighted 2.5 % Perc.:   679.8289 #> Weighted Median:        979.1790 #> Weighted Mean:         1014.0002 #> Weighted Mode:          869.9794 #> Weighted 97.5 % Perc.: 1517.4734 #> Max.:                  1705.5757 library(ggplot2)  plot_posterior(abc) +   geom_vline(xintercept = 1000, linetype = \"dashed\") +   coord_cartesian(xlim = c(100, 5000))"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"three-competing-models","dir":"Articles","previous_headings":"","what":"Three competing models","title":"Diagnostics, model selection, troubleshooting","text":"First, order perform model selection, need specify models . defining three separate slendr functions, encoding three population relationships diagrams . Note ’re trying infer time gene flow, simplicity, fix gene flow event different times (, reflected alternative model sketches ), just make models stand one another: Now, let’s specify priors using demografr’s templating syntax. saves us bit typing, making prior definition code bit consise easier read: Let’s also put together list tree-sequence summary functions observed summary statistics: Let’s validate ABC setup three models – important check slendr model functions defined correctly (set quiet = TRUE surpress writing full log output): way, can proceed generating simulated data inference using three models. ’ll perform three runs save appropriately named variables dataX, dataY, dataZ: total runtime ABC simulations 0 hours 55 minutes 51 seconds parallelized across 96 CPUs.","code":"modelX <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_1, T_2, T_3, gf) {   A <- population(\"A\", time = 1,   N = Ne_A)   B <- population(\"B\", time = T_1, N = Ne_B, parent = A)   C <- population(\"C\", time = T_2, N = Ne_C, parent = B)   D <- population(\"D\", time = T_3, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\"   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 50), list(B, 50), list(C, 50), list(D, 50),     strict = TRUE   )    return(list(model, samples)) }  modelY <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_1, T_2, T_3, gf) {   A <- population(\"A\", time = 1,   N = Ne_A)   B <- population(\"B\", time = T_1, N = Ne_B, parent = A)   C <- population(\"C\", time = T_2, N = Ne_C, parent = A)   D <- population(\"D\", time = T_3, N = Ne_D, parent = A)    gf <- gene_flow(from = A, to = B, start = 9000, end = 9301, rate = gf)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\"   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 50), list(B, 50), list(C, 50), list(D, 50),     strict = TRUE   )    return(list(model, samples)) }  modelZ <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_1, T_2, T_3, gf) {   A <- population(\"A\", time = 1,   N = Ne_A)   B <- population(\"B\", time = T_1, N = Ne_B, parent = A)   C <- population(\"C\", time = T_2, N = Ne_C, parent = A)   D <- population(\"D\", time = T_3, N = Ne_D, parent = C)    gf <- gene_flow(from = C, to = D, start = 9000, end = 9301, rate = gf)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\"   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 50), list(B, 50), list(C, 50), list(D, 50),     strict = TRUE   )    return(list(model, samples)) } priors <- list(   Ne... ~ runif(100, 10000),    T_1   ~ runif(1,    4000),   T_2   ~ runif(3000, 9000),   T_3   ~ runif(5000, 10000),    gf    ~ runif(0, 1) ) compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) }  compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) }  compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  functions <- list(   diversity = compute_diversity,   divergence = compute_divergence,   f4 = compute_f4 ) validate_abc(modelX, priors, functions, observed, quiet = TRUE,              sequence_length = 1e6, recombination_rate = 1e-8) validate_abc(modelY, priors, functions, observed, quiet = TRUE,              sequence_length = 1e6, recombination_rate = 1e-8) validate_abc(modelZ, priors, functions, observed, quiet = TRUE,              sequence_length = 1e6, recombination_rate = 1e-8) dataX <- simulate_abc(modelX, priors, functions, observed, iterations = 10000,                       sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8) dataY <- simulate_abc(modelY, priors, functions, observed, iterations = 10000,                       sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8) dataZ <- simulate_abc(modelZ, priors, functions, observed, iterations = 10000,                       sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8) abcX <- run_abc(dataX, engine = \"abc\", tol = 0.01, method = \"neuralnet\") abcY <- run_abc(dataY, engine = \"abc\", tol = 0.01, method = \"neuralnet\") abcZ <- run_abc(dataZ, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross-validation","title":"Diagnostics, model selection, troubleshooting","text":"model selection, ’s important perform cross-validation answer question whether ABC setup can even distinguish competing models. Without power , trying select best model wouldn’t make much sense. can done using demografr’s cross_validate() function built around abc’s function cv4postpr(). go much detail, function simply calls cv4postpr() hood, passing specified function arguments behalf user avoid unnecessary manual data munging (creating index vector, merging summary statistics sumstat parameter, etc.). details, read section “Model selection” vignette abc R package. one difference two functions cross_validate() removes need prepare character indices bind together summary statistic matrices different models—given demografr’s ABC output objects track information along internals, redundant, can perform cross-validation different ABC models simply calling : print result, get quick summary resulting confusion matrices diagnostic information: Similarly, can use plot() function visualize result. function, yet , internally calls abc’s plotting method internall, bonus option save figure PDF right plot() call (useful working remote server):  three models, three barplots shows often summary statistics sampled model classified likely coming one three models. words, absolutely perfect classification, barplot show just one three colors. barplot (results one model) shows multiple colors, means fraction simulated statistics model incorrectly classified another model. , detail interpretation, caveats, best practices, please consult abc R package vignette relevant statistical textbook. confusion matrices visualization suggest ABC can distinguish three models well. instance, modelX classified correctly 95 simulations total 100 cross-validation simulations, overall misclassification rate models 2.7%.","code":"models <- list(abcX, abcY, abcZ)  cv_selection <- cross_validate(models, nval = 100, tol = 0.01, method = \"neuralnet\") cv_selection #> Confusion matrix based on 100 samples for each model. #>  #> $tol0.01 #>        modelX modelY modelZ #> modelX     95      0      5 #> modelY      0     98      2 #> modelZ      0      1     99 #>  #>  #> Mean model posterior probabilities (neuralnet) #>  #> $tol0.01 #>        modelX modelY modelZ #> modelX 0.8877 0.0594 0.0529 #> modelY 0.0467 0.9336 0.0197 #> modelZ 0.0097 0.0237 0.9667 #>  #> $conf.matrix #> $conf.matrix$tol0.01 #>        modelX modelY modelZ #> modelX     95      0      5 #> modelY      0     98      2 #> modelZ      0      1     99 #>  #>  #> $probs #> $probs$tol0.01 #>             modelX     modelY     modelZ #> modelX 0.887682442 0.05943189 0.05288567 #> modelY 0.046703531 0.93360755 0.01968892 #> modelZ 0.009653286 0.02366436 0.96668236 plot(cv_selection)"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"model-selection","dir":"Articles","previous_headings":"","what":"Model selection","title":"Diagnostics, model selection, troubleshooting","text":"Armed confidence ability ABC correctly identify correct model based simulated data, can proceed selection best model empirical data set. can done function select_model() demografr’s convenience wrapper around abc’s function postpr: can make decision model selection inspecting summary() produced result: can see, modelX shows highest rate acceptance among simulations. Specifically, see proportion acceptance 87.1%. Similarly, looking Bayes factors, see “modelX” 156.8 times likely “modelY”, 7.1 likely “modelZ”. posterior probabilities computed using elaborate neural network method (, see details abc vignette), find probability “modelX” even overwhelming. fact, analysis shows 100% probabiliy correct model explain data. accurate conclusions? Well, take peek slendr model internally used generate “observed” summary statistics, see data indeed simulated code nearly identical one shown modelX. plotted, true model looks like :  appears can quite confident three models compatible data. However, move inferring parameters model, check whether best selected model can indeed capture important features data, case ABC represented summary statistics. order , demografr provides function call predict() performs posterior predictive check. , also look use functions gfit() gfitpca() implemented abc R package . Let’s start posterior predictive checks.","code":"models <- list(abcX, abcY, abcZ)  modsel <- select_model(models, tol = 0.03, method = \"neuralnet\") modsel #> Call:  #> abc::postpr(target = parts$target, index = parts$index, sumstat = parts$sumstat,  #>     tol = tol, method = \"neuralnet\") #> Data: #>  postpr.out$values (900 posterior samples) #> Models a priori: #>  modelX, modelY, modelZ #> Models a posteriori: #>  modelX, modelY, modelZ #>  #> Proportion of accepted simulations (rejection): #> modelX modelY modelZ  #> 0.8711 0.0056 0.1233  #>  #> Bayes factors: #>          modelX   modelY   modelZ #> modelX   1.0000 156.8000   7.0631 #> modelY   0.0064   1.0000   0.0450 #> modelZ   0.1416  22.2000   1.0000 #>  #>  #> Posterior model probabilities (neuralnet): #> modelX modelY modelZ  #>      1      0      0  #>  #> Bayes factors: #>             modelX      modelY      modelZ #> modelX      1.0000 332999.4682 523844.8406 #> modelY      0.0000      1.0000      1.5731 #> modelZ      0.0000      0.6357      1.0000 A <- population(\"A\", time = 1, N = 2000) B <- population(\"B\", time = 2000, N = 800, parent = A) C <- population(\"C\", time = 6000, N = 9000, parent = B) D <- population(\"D\", time = 8000, N = 4000, parent = C)  gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = 0.1)  example_model <- compile_model(   populations = list(A, B, C, D), gene_flow = gf,   generation_time = 1,   simulation_length = 10000 )  plot_model(example_model, proportions = TRUE)"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"posterior-predictive-checks","dir":"Articles","previous_headings":"","what":"Posterior predictive checks","title":"Diagnostics, model selection, troubleshooting","text":"Link: http://www.stat.columbia.edu/~gelman/research/published/A6n41.pdf one thing Simply speaking, fitting model estimating parameters using ABC, rely set summary statistics, assume capture important features true model represented data gathered. Performing posterior predictive checks involves estimating posterior distributions parameters interest data (.e. ABC inference) – something ’ve done modelX, modelY, modelZ – sampling parameters distributions generating distributions simulated summary statistics estimated models. , plot distributions simulated summary statistics together vertical line representing values observed statistics. Naturally, model can generate statistics compatible values observed real data can regard model sensible usable inference. Looking posterior predictive plots model X, can see observed statistics (vertical dashed lines) fall well within distributions statistics simulated posterior parameters model. suggests model (simplified must given complex reality), captures empoirical statistics quite well:    hand, looking model Z, instance, see although f4f_4 gene-flow detection statistic fits rather nicely, pairwise divergences populations completely statistics simulated posterior distributions. strongly suggests model wasn’t able capture features data.    can compare divergences models directly see model gives reasonable posterior predictive check results clearly:  can see posterior predictive checks nucleotide diversity little less clear extremely dramatic outliers ’s case divergence :   customization detailed analyses needed, can also extract data posterior simulations : However, note extract_prediction convenience function unnests, reformats, renames list-columns summary statistics stored predictions data frame . can processing based predictions object .","code":"plan(multisession, workers = availableCores()) predX <- predict(abcX, samples = 1000, posterior = \"unadj\") predY <- predict(abcY, samples = 1000, posterior = \"unadj\") predZ <- predict(abcZ, samples = 1000, posterior = \"unadj\") plot_prediction(predX) #> $diversity #>  #> $divergence #>  #> $f4 plot_prediction(predY) #> $diversity #>  #> $divergence #>  #> $f4 cowplot::plot_grid(   plot_prediction(predX, \"divergence\"),   plot_prediction(predY, \"divergence\"),   plot_prediction(predZ, \"divergence\"),   ncol = 1 ) cowplot::plot_grid(   plot_prediction(predX, \"diversity\"),   plot_prediction(predY, \"diversity\"),   plot_prediction(predZ, \"diversity\"),   ncol = 1 ) cowplot::plot_grid(   plot_prediction(predX, \"f4\"),   plot_prediction(predY, \"f4\"),   plot_prediction(predZ, \"f4\"),   ncol = 1 ) extract_prediction(predX, \"diversity\") #> $diversity #> # A tibble: 4,000 × 12 #>      rep   T_1   T_2   T_3     gf  Ne_A  Ne_B  Ne_C  Ne_D summary  stat    value #>    <int> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <chr>    <chr>   <dbl> #>  1     1 1218. 6392. 9831. 0.0627 1573.  987. 5493. 5879. diversi… dive… 5.89e-5 #>  2     1 1218. 6392. 9831. 0.0627 1573.  987. 5493. 5879. diversi… dive… 3.98e-5 #>  3     1 1218. 6392. 9831. 0.0627 1573.  987. 5493. 5879. diversi… dive… 9.35e-5 #>  4     1 1218. 6392. 9831. 0.0627 1573.  987. 5493. 5879. diversi… dive… 9.48e-5 #>  5     2  962. 5053. 6577. 0.0747 1105. 1215. 3420. 3951. diversi… dive… 4.94e-5 #>  6     2  962. 5053. 6577. 0.0747 1105. 1215. 3420. 3951. diversi… dive… 4.98e-5 #>  7     2  962. 5053. 6577. 0.0747 1105. 1215. 3420. 3951. diversi… dive… 9.83e-5 #>  8     2  962. 5053. 6577. 0.0747 1105. 1215. 3420. 3951. diversi… dive… 1.02e-4 #>  9     3  345. 4826. 9959. 0.294   473.  679. 7349. 6138. diversi… dive… 1.62e-5 #> 10     3  345. 4826. 9959. 0.294   473.  679. 7349. 6138. diversi… dive… 2.53e-5 #> # ℹ 3,990 more rows"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"additional-diagnostics-and-backwards-compatibility-with-the-abc-package","dir":"Articles","previous_headings":"","what":"Additional diagnostics and backwards compatibility with the abc package","title":"Diagnostics, model selection, troubleshooting","text":"mentioned , functionality behind cross_validate() implemented reformatting results demografr simulation inference functionality form necessary run functions abc package cv4abc() cv4postpr() behind scenes – task normally requires significant amount potentially error-prone bookkeeping part user. addition demografr’s function predict() implements posterior predictive checks, abc package provides additional functionality evaluating quality fit ABC model data, namely gfit() gfitpca(). section demonstrate functionality (potentially future abc functions) can applied demografr data little additional work. First, demografr provides function unpack() – applied object generated either simulate_abc() run_abc() – unpacks object encapsulating information describing simulation inference produced , individual components names matching “low-level” function arguments relevant functions anc package. includes gfit() gfitpca() mentioned , also functions cv4abc() cv4postpr(). unpack() works.","code":""},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"unpacking-a-demografr-object-to-low-level-components-used-by-the-abc-package","dir":"Articles","previous_headings":"Additional diagnostics and backwards compatibility with the abc package","what":"“Unpacking” a demografr object to low-level components used by the abc package","title":"Diagnostics, model selection, troubleshooting","text":"can see, unpack() function produced list object several elements: sumstat, index, param, target. ’s coincidence names list elements correspond function arguments various diagnostic functions abc package. way, demografr pre-generates information required functions (normally need prepared manually), can run without additional work whatsoever. instance, perform cross-validation model selection using abc’s functionality like . First, model-selection requires, well, multiple models select , unpack information three models: , simply run cv4postpr() normally , using information pre-generated unpack(): Unlike result cross_validate() , typing object cv4postpr_res help us, can get overview results applying function summary(): can see, can replicate result cross_validate() model selection combining functions unpack(), cv4postpr() summary(). course, using cross_validate() allows us one go straightforward way, hopefully demonstrates ’s magic behind demografr’s convenient functionality. just streamlines process ABC diagnostics avoids unnecessary (potentially error-prone) data processing. similar note, can also run abc functions gfit() gfitpca() (described vignette) exactly way. focus just code, leave interpretation discussion vignette: First, unpack results selected best-fitting model appropriate abc object obtained demografr function run_abc() : use elements parts list just created inputs gfit():    completeness, can run gfitpca() demografr results:  Based PCA, appears although model X model Y able generate summary statistics (areas captured colored “envelopes” 2D space) compatible observed values (cross), modelZ clearly .","code":"partsX <- unpack(abcX)  class(partsX) #> [1] \"list\" names(partsX) #> [1] \"sumstat\" \"index\"   \"param\"   \"target\" parts <- unpack(list(abcX, abcY, abcZ))  class(parts) #> [1] \"list\" names(parts) #> [1] \"sumstat\" \"index\"   \"param\"   \"target\" library(abc) # cv4postpr() is a function from the abc R package, not demografr! #> Loading required package: abc.data #> Loading required package: nnet #> Loading required package: quantreg #> Loading required package: SparseM #> Loading required package: MASS #>  #> Attaching package: 'MASS' #> The following object is masked from 'package:slendr': #>  #>     area #> Loading required package: locfit #> locfit 1.5-9.12   2025-03-05 cv4postpr_res <- cv4postpr(index = parts$index, sumstat = parts$sumstat, nval = 10, tols = 0.01, method = \"neuralnet\") summary(cv4postpr_res) #> Confusion matrix based on 10 samples for each model. #>  #> $tol0.01 #>        modelX modelY modelZ #> modelX     10      0      0 #> modelY      0     10      0 #> modelZ      0      0     10 #>  #>  #> Mean model posterior probabilities (neuralnet) #>  #> $tol0.01 #>        modelX modelY modelZ #> modelX 0.9508 0.0114 0.0378 #> modelY 0.1030 0.8783 0.0187 #> modelZ 0.0008 0.0271 0.9721 partsX <- unpack(abcX)  class(partsX) #> [1] \"list\" names(partsX) #> [1] \"sumstat\" \"index\"   \"param\"   \"target\" library(abc) # gfit() is a function from the abc R package, not demografr!  gfitX <- gfit(target = partsX$target, sumstat = partsX$sumstat, statistic = mean, nb.replicate = 100)  plot(gfitX, main=\"Histogram under H0 (model X)\") summary(gfitX) #> $pvalue #> [1] 0.37 #>  #> $s.dist.sim #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   2.936   3.393   3.792   3.925   4.350   7.145  #>  #> $dist.obs #> [1] 4.076438 partsY <- unpack(abcY)  gfitY <- gfit(target = partsY$target, sumstat = partsY$sumstat, statistic = mean, nb.replicate = 100)  plot(gfitY, main=\"Histogram under H0 (model Y)\") summary(gfitY) #> $pvalue #> [1] 0.21 #>  #> $s.dist.sim #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   2.717   3.099   3.407   3.536   3.818   5.478  #>  #> $dist.obs #> [1] 3.968966 partsZ <- unpack(abcZ)  gfitZ <- gfit(target = partsZ$target, sumstat = partsZ$sumstat, statistic = mean, nb.replicate = 100)  plot(gfitZ, main=\"Histogram under H0 (model Z)\") summary(gfitZ) #> $pvalue #> [1] 0.08 #>  #> $s.dist.sim #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   2.826   3.331   3.808   3.874   4.353   5.538  #>  #> $dist.obs #> [1] 5.032494 library(abc) # gfitpca() is a function from the abc R package, not demografr!  parts <- unpack(list(abcX, abcY, abcZ))  # this needs to be loaded because of a bug in abc dependency handling library(locfit) gfitpca(target = parts$target, sumstat = parts$sumstat, index = parts$index, cprob = 0.01,         xlim = c(-7, 7), ylim = c(-6, 3))"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"abc-cross-validation","dir":"Articles","previous_headings":"","what":"ABC cross-validation","title":"Diagnostics, model selection, troubleshooting","text":"Now finally point can infer parameters model data. However, , first check ABC setup can even estimate model parameters . seen just , abc package provides ABC cross-validation function cv4abc() demografr implements convenient interface form method cross_validate(). seen use method perform model selection, given list multiple ABC objects input. Instead, given single demografr ABC object (generated function run_abc()), performs ABC cross-validation can use gauge accuracy ABC sensitivity parameter estimates tolerance rate.","code":"cv_abc <- cross_validate(abcX, nval = 10, tols = c(0.005, 0.01, 0.05), method = \"neuralnet\") cv_abc_loclinear <- cross_validate(abcX, nval = 10, tols = c(0.005, 0.01, 0.05), method = \"loclinear\") cv_abc_rejection <- cross_validate(abcX, nval = 10, tols = c(0.005, 0.01, 0.05), method = \"rejection\") cv_abc #> Prediction error based on a cross-validation sample of 10 #>  #>               T_1         T_2         T_3          gf        Ne_A        Ne_B #> 0.005 0.115931446 0.021348771 0.038194294 0.309167517 0.020077626 0.012763087 #> 0.01  0.091075320 0.099796453 0.064480292 0.134594155 0.012453182 0.017957541 #> 0.05  0.061237866 0.132741819 0.094562080 0.111181948 0.004788782 0.055213568 #>              Ne_C        Ne_D #> 0.005 0.133038362 0.184171452 #> 0.01  0.065745262 0.281973594 #> 0.05  0.096448898 0.338678256 plot(cv_abc)"},{"path":"https://bodkan.net/demografr/articles/vignette-06-diagnostics.html","id":"parameter-inference","dir":"Articles","previous_headings":"","what":"Parameter inference","title":"Diagnostics, model selection, troubleshooting","text":"Now can finally estimate model parameters model seems explain data best – modelX. simulated data (hidden) true, known model, also visualize true parameter values vertical dashed lines compare values posterior distributions parameters.    bad, considering simulations ’ve thrown inference order save computational resources small vignette! can see modes inferred posterior distributions model parameters (colorful densities plotted ) line pretty much perfectly true values (dashed vertical lines). make concluding point even clearer (also demonstrate importance various validation procedures described , posterior predictive checks!) let’s say weren’t careful enough model selection simply assumed structure modelZ appropriate model data used inference split time parameters instead. complete non-sense show purely demonstration purposes!  can clearly see posterior distributions inferred ABC particular model completely failed capture true values.","code":"abcX #> Call: #> abc::abc(target = observed, param = data$parameters, sumstat = simulated,  #>     tol = 0.01, method = \"neuralnet\") #> Method: #> Non-linear regression via neural networks #> with correction for heteroscedasticity #>  #> Parameters: #> T_1, T_2, T_3, gf, Ne_A, Ne_B, Ne_C, Ne_D #>  #> Statistics: #> diversity_A, diversity_B, diversity_C, diversity_D, divergence_A_B, divergence_A_C, divergence_A_D, divergence_B_C, divergence_B_D, divergence_C_D, f4_A_B_C_D #>  #> Total number of simulations 10000  #>  #> Number of accepted simulations:  100 extract_summary(abcX) #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #> Warning in density.default(x, weights = weights): Selecting bandwidth *not* #> using 'weights' #>                             T_1      T_2      T_3          gf      Ne_A #> Min.:                  1425.751 2833.185 6536.967 -0.32010183  144.1305 #> Weighted 2.5 % Perc.:  1526.555 4419.209 7007.975 -0.22652541 1233.2805 #> Weighted Median:       2147.892 5819.360 8448.530  0.11570250 2080.5055 #> Weighted Mean:         2129.747 5725.272 8419.426  0.13775215 2132.1050 #> Weighted Mode:         2217.754 5896.542 8424.752  0.09495957 1869.5472 #> Weighted 97.5 % Perc.: 2713.950 6413.442 9392.346  0.50254407 3204.0996 #> Max.:                  3089.160 6721.522 9614.610  0.90031920 5063.1232 #>                             Ne_B      Ne_C      Ne_D #> Min.:                   304.7693  1550.589 -4883.706 #> Weighted 2.5 % Perc.:   364.2064  3934.065 -1714.943 #> Weighted Median:        853.8310  6922.173  2527.980 #> Weighted Mean:          879.6763  6788.551  2709.414 #> Weighted Mode:          873.5101  7258.315  2084.825 #> Weighted 97.5 % Perc.: 1527.3169 10811.460  7443.152 #> Max.:                  1580.1703 11699.557 10902.648 library(ggplot2) plot_posterior(abcX, param = \"T\") +   geom_vline(xintercept = c(2000, 6000, 8000), linetype = \"dashed\") plot_posterior(abcX, param = \"Ne\") +     geom_vline(xintercept = c(2000, 800, 9000, 4000), linetype = \"dashed\") plot_posterior(abcX, param = \"gf\") +   geom_vline(xintercept = 0.1, linetype = \"dashed\") +   coord_cartesian(xlim = c(0, 1)) plot_posterior(abcZ, param = \"T\") +   geom_vline(xintercept = c(2000, 6000, 8000), linetype = \"dashed\")"},{"path":"https://bodkan.net/demografr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Martin Petr. Author, maintainer.","code":""},{"path":"https://bodkan.net/demografr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Petr M (2025). demografr: Toolkit Simulation-Based Inference Population Genetics. R package version 0.1.0, https://github.com/bodkan/demografr.","code":"@Manual{,   title = {demografr: A Toolkit for Simulation-Based Inference in Population Genetics},   author = {Martin Petr},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/bodkan/demografr}, }"},{"path":"https://bodkan.net/demografr/index.html","id":"demografr-simulation-based-inference-for-population-genetics","dir":"","previous_headings":"","what":"A Toolkit for Simulation-Based Inference in Population Genetics","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"⚠️⚠️⚠️ Please note demografr still active development. ’d like notified updates releases, click “Watch” top main GitHub page. also keep eye changelog. ⚠️⚠️⚠️ goal demografr simplify streamline development simulation-based inference pipelines population genetics evolutionary biology, Approximate Bayesian Computation (ABC) parameter grid inferences, make reproducible. demografr also aims make inferences orders magnitude faster efficient leveraging tree sequences internal data structure computation engine. Unlike traditional ABC simulation-based approaches, generally involve custom-built pipelines scripts population genetic simulation computation summary statistics, demografr makes possible perform simulation, computation summary statistics, inference entirely R within single reproducible analysis script. eliminating need write custom simulation code scripting integration various population genetic tools computing summary statistics, lowers barrier new users facilitates reproducibility everyone regardless level experience eliminating many common sources bugs.","code":""},{"path":"https://bodkan.net/demografr/index.html","id":"how-does-demografr-help-with-abc","dir":"","previous_headings":"","what":"How does demografr help with ABC?","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"demografr streamlines every step typical ABC pipeline leveraging slendr framework building block simulation data analysis, making possible write complete simulation-based workflows entirely R. Specifically: slendr’s intuitive, interactive interface definning population genetic models makes easy encode even complex demographic models bare minimum R knowledge needed. demografr makes possible encode prior distributions parameters using familiar R interface resembling standard probabilistic statements, provides automated function simulates ABC replicates drawing parameters priors trivial, one-step manner. slendr embraces tree sequence default internal data structure, population genetic statistics can computed directly tree sequences using R functions part slendr’s statistical library. tree sequence never saved disk conversion file formats required, significantly speeds every workflow. demografr facilitates tight integration powerful R package abc automatically feeding simulation data inference diagnostics.","code":""},{"path":"https://bodkan.net/demografr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"can install development version demografr GitHub : Note requires R package devtools, can obtain simply running install.packages(\"devtools\"). demografr tightly linked slendr simulation package (fact, new developments slendr ale currently driven requirements demografr), also need development version slendr :","code":"devtools::install_github(\"bodkan/demografr\") devtools::install_github(\"bodkan/slendr\")"},{"path":"https://bodkan.net/demografr/index.html","id":"note-on-stability","dir":"","previous_headings":"Installation","what":"Note on stability","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"demografr much experimental stage point. Although inference “standard” demographic models (.e. estimating NeN_e, split times gene-flow parameters, etc.) already works nicely, long-term ambitions project much higher extend, instance, towards inferences spatial models models include selection. , please aware interface might change rather short notice accomodate features estimating parameters much complex models. want follow updates demografr, can also social media checking changelog time time.","code":""},{"path":"https://bodkan.net/demografr/index.html","id":"testing-the-r-package-in-an-online-rstudio-session","dir":"","previous_headings":"Installation","what":"Testing the R package in an online RStudio session","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"can open RStudio session test examples vignettes directly web browser clicking button (installation needed!):  case RStudio instance appears starting slowly, please patient (Binder freely available service limited computational resources). Binder crashes, try reloading web page, restart cloud session. get browser-based RStudio session, can navigate vignettes/ directory test examples !","code":""},{"path":"https://bodkan.net/demografr/index.html","id":"an-example-abc-pipeline","dir":"","previous_headings":"","what":"An example ABC pipeline","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"Note: much detailed explanation toy example can found following vignette. Imagine sequenced genomes individuals populations “”, “B”, “C”, “D”. Let’s also assume know populations phylogenetically related following way, indicated gene-flow event certain time past, don’t know anything else (.e., idea NeN_e, split times, proportion gene flow):  sequencing genomes individuals populations, computed nucleotide diversity populations, pairwise genetic divergence, f4f_4 statistic, observed following values (saved two standard R data frames): Nucleotide diversity population: Pairwise divergence d_X_Y populations X Y: Value following f4f_4-statistic:","code":"observed_diversity <- read.table(system.file(\"examples/basics_diversity.tsv\", package = \"demografr\"), header = TRUE)  observed_diversity #>   set    diversity #> 1   A 8.030512e-05 #> 2   B 3.288576e-05 #> 3   C 1.013804e-04 #> 4   D 8.910909e-05 observed_divergence <- read.table(system.file(\"examples/basics_divergence.tsv\", package = \"demografr\"), header = TRUE)  observed_divergence #>   x y   divergence #> 1 A B 0.0002378613 #> 2 A C 0.0002375761 #> 3 A D 0.0002379385 #> 4 B C 0.0001088217 #> 5 B D 0.0001157056 #> 6 C D 0.0001100633 observed_f4  <- read.table(system.file(\"examples/basics_f4.tsv\", package = \"demografr\"), header = TRUE)  observed_f4 #>   W X Y Z            f4 #> 1 A B C D -3.262146e-06"},{"path":"https://bodkan.net/demografr/index.html","id":"a-complete-abc-analysis-in-a-single-r-script","dir":"","previous_headings":"An example ABC pipeline","what":"A complete ABC analysis in a single R script","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"use demografr estimate NeN_e, split times populations, well rate indicated gene-flow event Approximate Bayesian Computation single R script:","code":"library(demografr) library(slendr) # running setup_env() first might be necessary to set up slendr's internal # simulation environment init_env()   # set up parallelization across all CPUs on the current machine library(future) plan(multisession, workers = availableCores())  #-------------------------------------------------------------------------------- # bind data frames with empirical summary statistics into a named list observed <- list(   diversity  = observed_diversity,   divergence = observed_divergence,   f4         = observed_f4 )  #-------------------------------------------------------------------------------- # define a model generating function using the slendr interface # (each of the function parameters correspond to a parameter we want to infer)  model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {   A <- population(\"A\", time = 1,    N = Ne_A)   B <- population(\"B\", time = T_AB, N = Ne_B, parent = A)   C <- population(\"C\", time = T_BC, N = Ne_C, parent = B)   D <- population(\"D\", time = T_CD, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf_BC)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\", serialize = FALSE   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 25), list(B, 25), list(C, 25), list(D, 25),     strict = TRUE   )    # when a specific sampling schedule is to be used, both model and samples   # must be returned by the function   return(list(model, samples)) }  #-------------------------------------------------------------------------------- # setup priors for model parameters  priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )  #-------------------------------------------------------------------------------- # define summary functions to be computed on simulated data (must be of the # same format as the summary statistics computed on empirical data)  compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) } compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) } compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  # the summary functions must be also bound to an R list named in the same # way as the empirical summary statistics  functions <- list(   diversity  = compute_diversity,   divergence = compute_divergence,   f4         = compute_f4 )  #-------------------------------------------------------------------------------- # validate the individual ABC components for correctness and consistency validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 1e-8)  #-------------------------------------------------------------------------------- # run ABC simulations data <- simulate_abc(   model, priors, functions, observed, iterations = 10000,   sequence_length = 50e6, recombination_rate = 1e-8, mutation_rate = 1e-8 )  #-------------------------------------------------------------------------------- # infer posterior distributions of parameters using the abc R package abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/index.html","id":"analysing-posterior-distributions-of-parameters","dir":"","previous_headings":"","what":"Analysing posterior distributions of parameters","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"run R script, end object called abc . object contains complete information results inference. particular, carries posterior samples parameters interest (NeN_e populations split times). instance, can get summary table parameter posteriors function extract_summary(): can also specify subset model parameters select, provide regular expression subsetting: course, can also visualize posterior distributions. Rather plotting many different distributions , let’s first check posterior distributions inferred NeN_e values:  Similarly, can take look inferred posteriors split times:  , finally, rate gene flow:  Additionally, full diagnostic functionality abc R package disposal:  Many diagnostic model selection functions implemented abc also supported demografr. information, see vignette.","code":"extract_summary(abc) #>                            Ne_A      Ne_B      Ne_C     Ne_D       T_AB #> Min.:                  1609.744  682.6193  7389.026 1846.029  -96.82908 #> Weighted 2.5 % Perc.:  1812.239  729.5846  7585.374 2691.913 1242.73702 #> Weighted Median:       2030.741  837.2673  8588.420 3785.385 1907.90411 #> Weighted Mean:         2019.638  841.6564  8674.207 3805.943 1949.07359 #> Weighted Mode:         2049.985  847.0022  8469.365 3642.722 1911.88919 #> Weighted 97.5 % Perc.: 2204.442  979.8260  9543.851 4742.401 2690.25909 #> Max.:                  2281.020 1038.0898 10965.790 5915.021 2921.08324 #>                            T_BC     T_CD       gf_BC #> Min.:                  5272.336 6608.244 -0.02143034 #> Weighted 2.5 % Perc.:  5630.022 7105.185  0.03373237 #> Weighted Median:       6133.605 7829.842  0.09864958 #> Weighted Mean:         6110.468 7814.700  0.10241672 #> Weighted Mode:         6236.457 7855.537  0.09655264 #> Weighted 97.5 % Perc.: 6603.022 8379.513  0.17629759 #> Max.:                  6838.022 8551.676  0.21388432 extract_summary(abc, param = \"gf_BC\") #>                              gf_BC #> Min.:                  -0.02143034 #> Weighted 2.5 % Perc.:   0.03373237 #> Weighted Median:        0.09864958 #> Weighted Mean:          0.10241672 #> Weighted Mode:          0.09655264 #> Weighted 97.5 % Perc.:  0.17629759 #> Max.:                   0.21388432 plot_posterior(abc, param = \"Ne\") plot_posterior(abc, param = \"T\") plot_posterior(abc, param = \"gf\") + ggplot2::coord_cartesian(xlim = c(0, 1)) plot(abc, param = \"Ne_C\")"},{"path":"https://bodkan.net/demografr/index.html","id":"additional-functionality","dir":"","previous_headings":"","what":"Additional functionality","title":"A Toolkit for Simulation-Based Inference in Population Genetics","text":"demografr also provides couple functions designed make troubleshooting little easier. instance, assuming priors set , can visualize prior distribution(s) like :","code":"plot_prior(priors, \"Ne\")"},{"path":"https://bodkan.net/demografr/reference/combine_data.character.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple individual grid simulation runs into one — combine_data.character","title":"Combine multiple individual grid simulation runs into one — combine_data.character","text":"Combine multiple individual grid simulation runs one","code":""},{"path":"https://bodkan.net/demografr/reference/combine_data.character.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple individual grid simulation runs into one — combine_data.character","text":"","code":"# S3 method for class 'character' combine_data(...)"},{"path":"https://bodkan.net/demografr/reference/combine_data.character.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple individual grid simulation runs into one — combine_data.character","text":"... Either list objects class demografr_abc_sims produced function simulate_abc, individual objects class given standard function arguments, paths 'rds' files containing serializations demografr_abc_sims objects.","code":""},{"path":"https://bodkan.net/demografr/reference/combine_data.character.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple individual grid simulation runs into one — combine_data.character","text":"combined object class demografr_abc_sims","code":""},{"path":"https://bodkan.net/demografr/reference/combine_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple individual ABC simulation runs into one — combine_data","title":"Combine multiple individual ABC simulation runs into one — combine_data","text":"Combine multiple individual ABC simulation runs one","code":""},{"path":"https://bodkan.net/demografr/reference/combine_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple individual ABC simulation runs into one — combine_data","text":"","code":"combine_data(...)"},{"path":"https://bodkan.net/demografr/reference/combine_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple individual ABC simulation runs into one — combine_data","text":"... Either list objects class demografr_abc_sims produced function simulate_abc, individual objects class given standard function arguments, paths 'rds' files containing serializations demografr_abc_sims objects.","code":""},{"path":"https://bodkan.net/demografr/reference/combine_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple individual ABC simulation runs into one — combine_data","text":"combined object class demografr_abc_sims","code":""},{"path":"https://bodkan.net/demografr/reference/combine_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple individual ABC simulation runs into one — combine_data","text":"","code":"library(slendr) init_env(quiet = TRUE)  # simulate three runs of a slendr model across a parameter grid model <- function(Ne_p1, Ne_p2, Ne_p3, Ne_p4) {   p1 <- population(\"p1\", time = 1, N = 1000)   p2 <- population(\"p2\", time = 2000, N = 3000, parent = p1)    model <- compile_model(     populations = list(p1, p2),     generation_time = 1,     simulation_length = 10000, serialize = FALSE   )    return(model) }  grid <- expand.grid(Ne_p1 = c(10, 100), Ne_p2 = c(10, 100))  compute_diversity <- function(ts) {   samples <- list(ts_samples(ts)$name)   ts_diversity(ts, sample_sets = samples, mode = \"branch\") } functions <- list(diversity = compute_diversity)  nreps <- 1 run1 <- simulate_grid(model, grid, functions, replicates = nreps,                       sequence_length = 10000, recombination_rate = 0) run2 <- simulate_grid(model, grid, functions, replicates = nreps,                       sequence_length = 10000, recombination_rate = 0)  # combine both simulation runs combine_data(run1, run2) #> # A tibble: 8 × 4 #>     rep Ne_p1 Ne_p2 diversity        #>   <int> <dbl> <dbl> <list>           #> 1     1    10    10 <tibble [1 × 2]> #> 2     1   100    10 <tibble [1 × 2]> #> 3     1    10   100 <tibble [1 × 2]> #> 4     1   100   100 <tibble [1 × 2]> #> 5     2    10    10 <tibble [1 × 2]> #> 6     2   100    10 <tibble [1 × 2]> #> 7     2    10   100 <tibble [1 × 2]> #> 8     2   100   100 <tibble [1 × 2]>"},{"path":"https://bodkan.net/demografr/reference/cross_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Run cross-validation routines of the abc R package — cross_validate","title":"Run cross-validation routines of the abc R package — cross_validate","text":"function convenience wrapper around functions cv4postpr anc::cv4abc R package abc","code":""},{"path":"https://bodkan.net/demografr/reference/cross_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run cross-validation routines of the abc R package — cross_validate","text":"","code":"cross_validate(x, nval, tols, method, ...)"},{"path":"https://bodkan.net/demografr/reference/cross_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run cross-validation routines of the abc R package — cross_validate","text":"x list objects class demografr_sims_abc (representing ABC inference result) function abc::cv4postpr, object demografr_abc.abc function abc::cv4abc nval, tols, method Required arguments abc::cv4postpr ... optional arguments passed abc::cv4postpr","code":""},{"path":"https://bodkan.net/demografr/reference/cross_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run cross-validation routines of the abc R package — cross_validate","text":"Object class cv4postpr demografr_cv","code":""},{"path":"https://bodkan.net/demografr/reference/cross_validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run cross-validation routines of the abc R package — cross_validate","text":"","code":"##################################################### # can we even distinguish between competing models?  if (FALSE) { # \\dontrun{ # read a list of three different ABC models models <- lapply(c(\"X\", \"Y\", \"Z\"), function(i) { readRDS(url(paste0( \"raw.githubusercontent.com/bodkan/demografr/refs/heads/main/inst/examples/downstream_abc\", i, \".rds\" ))) })  # note that each element of the list is, indeed, a demografr ABC result models[[1]]   # run cross validation to find out if we have even the power to distinguish # our competing models(see the abc package vignette for interpretation) cv_models <- cross_validate(models, nval = 10, tols = c(0.005, 0.01, 0.05), method = \"neuralnet\") cv_model  ##################################################### # can our model even estimate the parameters?  # read an example result of an ABC inference abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  # perform cross-validation cv_params <- cross_validate(abc_res, nval = 10, tols = c(0.005, 0.01, 0.05),                             method = \"neuralnet\") cv_params } # }"},{"path":"https://bodkan.net/demografr/reference/extract_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract inferred posterior(s) as a standard data frame — extract_posterior","title":"Extract inferred posterior(s) as a standard data frame — extract_posterior","text":"Extract inferred posterior(s) standard data frame","code":""},{"path":"https://bodkan.net/demografr/reference/extract_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract inferred posterior(s) as a standard data frame — extract_posterior","text":"","code":"extract_posterior(abc, param = NULL, posterior = c(\"adj\", \"unadj\"))"},{"path":"https://bodkan.net/demografr/reference/extract_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract inferred posterior(s) as a standard data frame — extract_posterior","text":"abc object produced run_abc param character vector containing either parameter names summarize, regex-like matches used subsetting. NULL (default), parameters extracted. posterior \"adj\"-usted \"unadj\"-usted posterior extracted? (Default \"adj\").","code":""},{"path":"https://bodkan.net/demografr/reference/extract_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract inferred posterior(s) as a standard data frame — extract_posterior","text":"data frame long format posterior values parameters","code":""},{"path":"https://bodkan.net/demografr/reference/extract_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract inferred posterior(s) as a standard data frame — extract_posterior","text":"","code":"# read example ABC result with an inferred joint posterior distribution abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  # extract the entire posterior sample for all parameters as a data frame extract_posterior(abc_res) #> # A tibble: 800 × 2 #>    param     value #>    <chr>     <dbl> #>  1 Ne_A  1787.     #>  2 Ne_B   975.     #>  3 Ne_C  8934.     #>  4 Ne_D  3999.     #>  5 T_AB  2161.     #>  6 T_BC  6087.     #>  7 T_CD  8094.     #>  8 gf_BC    0.0305 #>  9 Ne_A  2105.     #> 10 Ne_B   807.     #> # ℹ 790 more rows  # extract the posterior sample for one parameter extract_posterior(abc_res, param = \"Ne_A\") #> # A tibble: 100 × 2 #>    param value #>    <chr> <dbl> #>  1 Ne_A  1787. #>  2 Ne_A  2105. #>  3 Ne_A  2176. #>  4 Ne_A  1924. #>  5 Ne_A  1981. #>  6 Ne_A  2222. #>  7 Ne_A  1868. #>  8 Ne_A  1989. #>  9 Ne_A  1955. #> 10 Ne_A  2034. #> # ℹ 90 more rows  # extract posterior samples for parameters matching a regex extract_posterior(abc_res, param = \"^Ne_\") #> # A tibble: 400 × 2 #>    param value #>    <chr> <dbl> #>  1 Ne_A  1787. #>  2 Ne_B   975. #>  3 Ne_C  8934. #>  4 Ne_D  3999. #>  5 Ne_A  2105. #>  6 Ne_B   807. #>  7 Ne_C  8588. #>  8 Ne_D  3602. #>  9 Ne_A  2176. #> 10 Ne_B   845. #> # ℹ 390 more rows"},{"path":"https://bodkan.net/demografr/reference/extract_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Unnest the predicted values of a given statistic from the simulated data — extract_prediction","title":"Unnest the predicted values of a given statistic from the simulated data — extract_prediction","text":"Unnest predicted values given statistic simulated data","code":""},{"path":"https://bodkan.net/demografr/reference/extract_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unnest the predicted values of a given statistic from the simulated data — extract_prediction","text":"","code":"extract_prediction(data, stat)"},{"path":"https://bodkan.net/demografr/reference/extract_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unnest the predicted values of a given statistic from the simulated data — extract_prediction","text":"data Data posterior simulations performed via predict.demografr_abc_sims stat tree-sequence summary statistic extract? NULL, summary statistics returned.","code":""},{"path":"https://bodkan.net/demografr/reference/extract_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unnest the predicted values of a given statistic from the simulated data — extract_prediction","text":"Data frame object containing columns values parameters sampled   posterior, column \"summary\" containing name summary statistic computed   combination parameters, column \"stat\" containing exact summary   statistic computed (useful case multiple values summary statistic computed   tree-sequence function), column \"value\" containing value.","code":""},{"path":"https://bodkan.net/demografr/reference/extract_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unnest the predicted values of a given statistic from the simulated data — extract_prediction","text":"","code":"if (FALSE) { # \\dontrun{ # read statistics computed from posterior sample simulations pred <- readRDS(url(paste0( \"https://raw.githubusercontent.com/bodkan/demografr/\", \"refs/heads/main/inst/examples/downstream_predX.rds\" )))  # note the columns `diversity`, `divergence`, and `f4` pred  # extract_prediction() is a convenience function which unpacks the given # summary statistic in a normal data frame column (here `diversity`) extract_prediction(pred, \"diversity\") } # }"},{"path":"https://bodkan.net/demografr/reference/extract_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract table of estimated model parameters — extract_summary","title":"Extract table of estimated model parameters — extract_summary","text":"Extract table estimated model parameters","code":""},{"path":"https://bodkan.net/demografr/reference/extract_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract table of estimated model parameters — extract_summary","text":"","code":"extract_summary(abc, param = NULL)"},{"path":"https://bodkan.net/demografr/reference/extract_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract table of estimated model parameters — extract_summary","text":"abc ABC object generated run_abc param character vector containing either parameter names summarize, regex-like matches used subsetting. NULL (default), parameters extracted.","code":""},{"path":"https://bodkan.net/demografr/reference/extract_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract table of estimated model parameters — extract_summary","text":"data frame object posterior summary statistics","code":""},{"path":"https://bodkan.net/demografr/reference/extract_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract table of estimated model parameters — extract_summary","text":"","code":"# read example ABC result with an inferred joint posterior distribution abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  extract_summary(abc_res) #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #> Warning: Selecting bandwidth *not* using 'weights' #>                            Ne_A      Ne_B      Ne_C     Ne_D       T_AB #> Min.:                  1609.744  682.6193  7389.026 1846.029  -96.82908 #> Weighted 2.5 % Perc.:  1812.239  729.5846  7585.374 2691.913 1242.73702 #> Weighted Median:       2030.741  837.2673  8588.420 3785.385 1907.90411 #> Weighted Mean:         2019.638  841.6564  8674.207 3805.943 1949.07359 #> Weighted Mode:         2049.985  847.0022  8469.365 3642.722 1911.88919 #> Weighted 97.5 % Perc.: 2204.442  979.8260  9543.851 4742.401 2690.25909 #> Max.:                  2281.020 1038.0898 10965.790 5915.021 2921.08324 #>                            T_BC     T_CD       gf_BC #> Min.:                  5272.336 6608.244 -0.02143034 #> Weighted 2.5 % Perc.:  5630.022 7105.185  0.03373237 #> Weighted Median:       6133.605 7829.842  0.09864958 #> Weighted Mean:         6110.468 7814.700  0.10241672 #> Weighted Mode:         6236.457 7855.537  0.09655264 #> Weighted 97.5 % Perc.: 6603.022 8379.513  0.17629759 #> Max.:                  6838.022 8551.676  0.21388432"},{"path":"https://bodkan.net/demografr/reference/hist.demografr_abc.abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot histogram of posterior distribution(s) — hist.demografr_abc.abc","title":"Plot histogram of posterior distribution(s) — hist.demografr_abc.abc","text":"Plot histogram posterior distribution(s)","code":""},{"path":"https://bodkan.net/demografr/reference/hist.demografr_abc.abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot histogram of posterior distribution(s) — hist.demografr_abc.abc","text":"","code":"# S3 method for class 'demografr_abc.abc' hist(x, param = NULL, ...)"},{"path":"https://bodkan.net/demografr/reference/hist.demografr_abc.abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot histogram of posterior distribution(s) — hist.demografr_abc.abc","text":"x ABC object generated run_abc param character vector containing either parameter names summarize, regex-like matches used subsetting. NULL (default), parameters extracted. ... Formal ellipsis argument plot method (unused)","code":""},{"path":"https://bodkan.net/demografr/reference/hist.demografr_abc.abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot histogram of posterior distribution(s) — hist.demografr_abc.abc","text":"base R histogram plot","code":""},{"path":"https://bodkan.net/demografr/reference/hist.demografr_abc.abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot histogram of posterior distribution(s) — hist.demografr_abc.abc","text":"","code":"# read inferred posterior distribution object from an example ABC run abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  # plot histograms of posteriors for all parameters (in sequence) # hist(abc_res)  # plot only selected posteriors hist(abc_res, param = \"gf_BC\")  hist(abc_res, param = \"^Ne_\")"},{"path":"https://bodkan.net/demografr/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://bodkan.net/demografr/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://bodkan.net/demografr/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://bodkan.net/demografr/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"https://bodkan.net/demografr/reference/plot.demografr_abc.abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot diagnostics of posterior distribution(s) — plot.demografr_abc.abc","title":"Plot diagnostics of posterior distribution(s) — plot.demografr_abc.abc","text":"Plot diagnostics posterior distribution(s)","code":""},{"path":"https://bodkan.net/demografr/reference/plot.demografr_abc.abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot diagnostics of posterior distribution(s) — plot.demografr_abc.abc","text":"","code":"# S3 method for class 'demografr_abc.abc' plot(x, param = NULL, ...)"},{"path":"https://bodkan.net/demografr/reference/plot.demografr_abc.abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot diagnostics of posterior distribution(s) — plot.demografr_abc.abc","text":"x ABC object generated run_abc param character vector containing either parameter names summarize, regex-like matches used subsetting. NULL (default), parameters extracted. ... Formal ellipsis argument plot method (unused)","code":""},{"path":"https://bodkan.net/demografr/reference/plot.demografr_abc.abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot diagnostics of posterior distribution(s) — plot.demografr_abc.abc","text":"Used exclusively printing","code":""},{"path":"https://bodkan.net/demografr/reference/plot.demografr_abc.abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot diagnostics of posterior distribution(s) — plot.demografr_abc.abc","text":"","code":"# read inferred posterior distribution object from an example ABC run abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  # plot diagnostics for all parameters (in sequence) # plot(abc_res)  # plot diagnostics only for selected parameters plot(abc_res, param = \"^Ne_\")     plot(abc_res, param = \"gf_BC\")"},{"path":"https://bodkan.net/demografr/reference/plot_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot posterior distribution of given parameters — plot_posterior","title":"Plot posterior distribution of given parameters — plot_posterior","text":"Plot posterior distribution given parameters","code":""},{"path":"https://bodkan.net/demografr/reference/plot_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot posterior distribution of given parameters — plot_posterior","text":"","code":"plot_posterior(   abc,   param = NULL,   posterior = c(\"adj\", \"unadj\"),   facets = FALSE,   file = NULL,   ... )"},{"path":"https://bodkan.net/demografr/reference/plot_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot posterior distribution of given parameters — plot_posterior","text":"abc ABC object generated run_abc param character vector containing either parameter names summarize, regex-like matches used subsetting. NULL (default), parameters extracted. posterior \"adj\"-usted \"unadj\"-usted posterior extracted? (Default \"adj\"). facets individual distributions plotted separate facets? Default FALSE. file Output file figure saved via ggsave ... Optional argument passed ggsave","code":""},{"path":"https://bodkan.net/demografr/reference/plot_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot posterior distribution of given parameters — plot_posterior","text":"ggplot2 plot object","code":""},{"path":"https://bodkan.net/demografr/reference/plot_posterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot posterior distribution of given parameters — plot_posterior","text":"","code":"# read an example result of an ABC inference abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  # plotting posteriors of all parameters at once doesn't make much sense # plot_posterior(abc_res)  # this is better plot_posterior(abc_res, facets = TRUE)   # this is perhaps even better plot_posterior(abc_res, param = \"^Ne_\")"},{"path":"https://bodkan.net/demografr/reference/plot_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the results of a posterior predictive check for a given summary statistic — plot_prediction","title":"Plot the results of a posterior predictive check for a given summary statistic — plot_prediction","text":"Plot results posterior predictive check given summary statistic","code":""},{"path":"https://bodkan.net/demografr/reference/plot_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the results of a posterior predictive check for a given summary statistic — plot_prediction","text":"","code":"plot_prediction(data, stat = NULL, file = NULL, facets = TRUE, ...)"},{"path":"https://bodkan.net/demografr/reference/plot_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the results of a posterior predictive check for a given summary statistic — plot_prediction","text":"data Data frame predictions generated ABC posteriors, generated predict function stat tree-sequence summary statistic extract? NULL, summary statistics visualized. file Output path PDF figure saved facets summary statistic plotted facet (default TRUE)? ... Optional argument passed ggsave","code":""},{"path":"https://bodkan.net/demografr/reference/plot_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the results of a posterior predictive check for a given summary statistic — plot_prediction","text":"file = NULL, ggplot2 object (list objects,   multiple summary statistics visualized), otherwise nothing returned   plots instead saved file.","code":""},{"path":"https://bodkan.net/demografr/reference/plot_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the results of a posterior predictive check for a given summary statistic — plot_prediction","text":"","code":"if (FALSE) { # \\dontrun{ # read statistics computed from posterior sample simulations pred <- readRDS(url(paste0( \"https://raw.githubusercontent.com/bodkan/demografr/\", \"refs/heads/main/inst/examples/downstream_predX.rds\" )))  # note the columns `diversity`, `divergence`, and `f4` pred  # extract_prediction() is a convenience function which unpacks the given # summary statistic in a normal data frame column (here `diversity`) extract_prediction(pred, \"diversity\")  # we can also plot the posterior predictive distributions for all statistics plot_prediction(pred, \"diversity\") } # }"},{"path":"https://bodkan.net/demografr/reference/plot_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prior distribution(s) — plot_prior","title":"Plot prior distribution(s) — plot_prior","text":"Plot prior distribution(s)","code":""},{"path":"https://bodkan.net/demografr/reference/plot_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prior distribution(s) — plot_prior","text":"","code":"plot_prior(   x,   param = NULL,   facets = FALSE,   file = NULL,   replicates = 10000,   geom = ggplot2::geom_density,   ... )"},{"path":"https://bodkan.net/demografr/reference/plot_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prior distribution(s) — plot_prior","text":"x Either object class demografr_abc, list prior sampling statements param character vector containing either parameter names summarize, regex-like matches used subsetting. NULL (default), parameters extracted. facets individual parameters plotting facet ? file Output file figure saved via ggsave replicates many samples simulate prior plotting? geom Either ggplot2::geom_histogram ggplot2::geom_density ... Optional argument passed ggsave","code":""},{"path":"https://bodkan.net/demografr/reference/plot_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prior distribution(s) — plot_prior","text":"ggplot2 plot object","code":""},{"path":"https://bodkan.net/demografr/reference/plot_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prior distribution(s) — plot_prior","text":"","code":"priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )  # as with many other distribution plotting functions, plotting everything # at once doesn't make much sense # plot_prior(priors)  # it's better to visualize together distributions of the same scale # plot_prior(priors, \"^Ne\") plot_prior(priors, \"gf\") + ggplot2::xlim(0, 1)"},{"path":"https://bodkan.net/demografr/reference/predict.demografr_abc.abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate summary statistics from the inferred posterior distribution of parameters — predict.demografr_abc.abc","title":"Generate summary statistics from the inferred posterior distribution of parameters — predict.demografr_abc.abc","text":"function draws parameter values posterior distribution internally runs function simulate_grid run simulations sampled parameters compute tree-sequence summary statistics","code":""},{"path":"https://bodkan.net/demografr/reference/predict.demografr_abc.abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate summary statistics from the inferred posterior distribution of parameters — predict.demografr_abc.abc","text":"","code":"# S3 method for class 'demografr_abc.abc' predict(   object,   samples,   stat = NULL,   posterior = c(\"adj\", \"unadj\"),   strict = FALSE,   functions = NULL,   ... )"},{"path":"https://bodkan.net/demografr/reference/predict.demografr_abc.abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate summary statistics from the inferred posterior distribution of parameters — predict.demografr_abc.abc","text":"object ABC object generated run_abc samples Number draws posterior distribution simulate stat tree-sequence summary statistic compute? NULL, summary statistics computed. posterior 'unadj'usted 'adj'usted parameters sampled? Default (recommended) value 'unadj'usted. strict parameter combinations leading invalid slendr models treated error? Default TRUE. set FALSE, invalid simulations simply dropped, informative message. parameter internally passed function simulate_grid() performs simulations across sampled parameter matrix. functions named list summary statistic tree-sequence functions applied simulated tree sequence. NULL (default), summary statistics computed used ABC inference . Otherwise, custom tree-sequence summary statistics can provided. ... formal argument predict generic method (unused)","code":""},{"path":"https://bodkan.net/demografr/reference/predict.demografr_abc.abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate summary statistics from the inferred posterior distribution of parameters — predict.demografr_abc.abc","text":"data frame object results posterior simulations, values  summary statistic stored list-column (.e. format used  function simulate_grid, predictions generated internally using","code":""},{"path":"https://bodkan.net/demografr/reference/predict.demografr_abc.abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate summary statistics from the inferred posterior distribution of parameters — predict.demografr_abc.abc","text":"","code":"if (FALSE) { # \\dontrun{ # read statistics computed from posterior sample simulations # the `pred` object was produced by the following call: #    pred <- predict(abc, samples = 1000, posterior = \"unadj\") # (where `abc` is the product of the `run_abc()` function) pred <- readRDS(url(paste0( \"https://raw.githubusercontent.com/bodkan/demografr/\", \"refs/heads/main/inst/examples/downstream_predX.rds\" )))  # note the columns `diversity`, `divergence`, and `f4` pred  # extract_prediction() is a convenience function which unpacks the given # summary statistic in a normal data frame column (here `diversity`) extract_prediction(pred, \"diversity\")  # we can also plot the posterior predictive distributions for all statistics plot_prediction(stats, \"diversity\") plot_prediction(stats, \"divergence\") } # }"},{"path":"https://bodkan.net/demografr/reference/print.demografr_abc_sims.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a brief summary of a set of demografr simulations — print.demografr_abc_sims","title":"Print a brief summary of a set of demografr simulations — print.demografr_abc_sims","text":"Print brief summary set demografr simulations","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_abc_sims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a brief summary of a set of demografr simulations — print.demografr_abc_sims","text":"","code":"# S3 method for class 'demografr_abc_sims' print(x, ...)"},{"path":"https://bodkan.net/demografr/reference/print.demografr_abc_sims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a brief summary of a set of demografr simulations — print.demografr_abc_sims","text":"x object class demografr_abc_sims, generated simulate_abc","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_abc_sims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a brief summary of a set of demografr simulations — print.demografr_abc_sims","text":"Used exclusively printing","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_abc","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_abc","text":"Print brief summary result abc::cv4postpr function","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_abc","text":"","code":"# S3 method for class 'demografr_cv_abc' print(x, ...)"},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_abc","text":"x object class demografr_cv, generated run_cv","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_abc","text":"Used exclusively printing","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_modsel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_modsel","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_modsel","text":"Print brief summary result abc::cv4postpr function","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_modsel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_modsel","text":"","code":"# S3 method for class 'demografr_cv_modsel' print(x, ...)"},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_modsel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_modsel","text":"x object class demografr_cv, generated run_cv","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_cv_modsel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a brief summary of the result of the abc::cv4postpr function — print.demografr_cv_modsel","text":"Used exclusively printing","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_postpr.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a brief summary of the result of the abc::postpr function — print.demografr_postpr","title":"Print a brief summary of the result of the abc::postpr function — print.demografr_postpr","text":"Print brief summary result abc::postpr function","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_postpr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a brief summary of the result of the abc::postpr function — print.demografr_postpr","text":"","code":"# S3 method for class 'demografr_postpr' print(x, ...)"},{"path":"https://bodkan.net/demografr/reference/print.demografr_postpr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a brief summary of the result of the abc::postpr function — print.demografr_postpr","text":"x object class demografr_postpr, generated model_selection","code":""},{"path":"https://bodkan.net/demografr/reference/print.demografr_postpr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a brief summary of the result of the abc::postpr function — print.demografr_postpr","text":"Used exclusively printing","code":""},{"path":"https://bodkan.net/demografr/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. slendr init_env","code":""},{"path":"https://bodkan.net/demografr/reference/run_abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform ABC on data generated by simulate_abc — run_abc","title":"Perform ABC on data generated by simulate_abc — run_abc","text":"Runs selected ABC method simulated data using R package abc inference engine.","code":""},{"path":"https://bodkan.net/demografr/reference/run_abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform ABC on data generated by simulate_abc — run_abc","text":"","code":"run_abc(data, engine = \"abc\", stat = NULL, ...)"},{"path":"https://bodkan.net/demografr/reference/run_abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform ABC on data generated by simulate_abc — run_abc","text":"data Simulated data set produced simulate_abc engine ABC engine use? current version demografr, valid choice \"abc\". stat simulated summary statistics use inference? NULL (default), simulated statistics used. ... Additional arguments passed abc function abc package","code":""},{"path":"https://bodkan.net/demografr/reference/run_abc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform ABC on data generated by simulate_abc — run_abc","text":"function serves wrapper around function abc R package abc. function arguments except data passed abc function, appropriately unpacking prior sample matrix, binding together matrices observed statistics simulated statistics format required inference function. function exists avoid need manually track parameter matrices summary statistics inputs abc function acts entirely transparently. , implementation details can found abc vignette manpage can access typing ?abc::abc.","code":""},{"path":"https://bodkan.net/demografr/reference/run_abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform ABC on data generated by simulate_abc — run_abc","text":"","code":"slendr::check_dependencies(python = TRUE, quit = TRUE)  library(demografr)  library(slendr) init_env(quiet = TRUE)  ################################################## # define a model  model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {   A <- population(\"A\", time = 1,    N = Ne_A)   B <- population(\"B\", time = T_AB, N = Ne_B, parent = A)   C <- population(\"C\", time = T_BC, N = Ne_C, parent = B)   D <- population(\"D\", time = T_CD, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf_BC)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\", serialize = FALSE   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 25), list(B, 25), list(C, 25), list(D, 25),     strict = TRUE   )    # when a specific sampling schedule is to be used, both model and samples   # must be returned by the function   return(list(model, samples)) }  ################################################## # set up priors  priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )  ################################################## # prepare a list of empirical summary statistics  observed_diversity <- read.table(   system.file(\"examples/basics_diversity.tsv\", package = \"demografr\"),   header = TRUE ) observed_divergence <- read.table(   system.file(\"examples/basics_divergence.tsv\", package = \"demografr\"),   header = TRUE ) observed_f4  <- read.table(   system.file(\"examples/basics_f4.tsv\", package = \"demografr\"),   header = TRUE ) observed <- list(   diversity  = observed_diversity,   divergence = observed_divergence,   f4         = observed_f4  )  ################################################## # prepare a list of simulated summary statistics  compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) } compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) } compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  functions <- list(   diversity  = compute_diversity,   divergence = compute_divergence,   f4         = compute_f4 )  ################################################## # simulate data from a single model run # (step #1 of a single ABC replicate simulation)  ts <- simulate_model(model, priors, sequence_length = 1e6, recombination_rate = 1e-8)  ################################################## # simulate data from a single model run # (step #2 of a single ABC replicate simulation)  summarise_data(ts, functions) #> $diversity #> # A tibble: 4 × 2 #>   set   diversity #>   <chr>     <dbl> #> 1 A             0 #> 2 B             0 #> 3 C             0 #> 4 D             0 #>  #> $divergence #> # A tibble: 6 × 3 #>   x     y     divergence #>   <chr> <chr>      <dbl> #> 1 A     B              0 #> 2 A     C              0 #> 3 A     D              0 #> 4 B     C              0 #> 5 B     D              0 #> 6 C     D              0 #>  #> $f4 #> # A tibble: 1 × 5 #>   W     X     Y     Z        f4 #>   <chr> <chr> <chr> <chr> <dbl> #> 1 A     B     C     D         0 #>   ################################################## # validate all components of the ABC inference pipeline  validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 1e-8) #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne_A ✅ #>   - Ne_B ✅ #>   - Ne_C ✅ #>   - Ne_D ✅ #>   - T_AB ✅ #>   - T_BC ✅ #>   - T_CD ✅ #>   - gf_BC ✅ #> --------------------------------------------------------------------- #> The model is a slendr function #> --------------------------------------------------------------------- #> Checking the return statement of the model function... ✅ #> --------------------------------------------------------------------- #> Checking the presence of required model function arguments...--------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #>   - divergence ✅ #>   - f4 ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #>   - divergence [data frame] ✅ #>   - f4 [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup!  # # we're skipping the remaining steps because they are extremely # computationally intensive for the scope of this example #  ################################################## # set up paralelization  # library(future) # plan(multisession, workers = availableCores())  ################################################## # simulate data (summary statistics)  # data <- simulate_abc( #   model, priors, functions, observed, iterations = 10000, #   sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8 # )  ################################################## # perform ABC inference  # abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/reference/sample_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample value from a given prior sampling formula object — sample_prior","title":"Sample value from a given prior sampling formula object — sample_prior","text":"Sample value given prior sampling formula object","code":""},{"path":"https://bodkan.net/demografr/reference/sample_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample value from a given prior sampling formula object — sample_prior","text":"","code":"sample_prior(f)"},{"path":"https://bodkan.net/demografr/reference/sample_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample value from a given prior sampling formula object — sample_prior","text":"f Formula-based prior sampling expression <variable> ~ <sampling statement>","code":""},{"path":"https://bodkan.net/demografr/reference/sample_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample value from a given prior sampling formula object — sample_prior","text":"list two elements: \"variable\" containing name sampled variable,   \"value\" containing actual value sampled prior.","code":""},{"path":"https://bodkan.net/demografr/reference/select_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform selection between different ABC models — select_model","title":"Perform selection between different ABC models — select_model","text":"function internally uses abc::postpr computing posterior probabilities models, Bayes factors, etc., order aid selection likely model.","code":""},{"path":"https://bodkan.net/demografr/reference/select_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform selection between different ABC models — select_model","text":"","code":"select_model(models, tol, ...)"},{"path":"https://bodkan.net/demografr/reference/select_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform selection between different ABC models — select_model","text":"models list objects class demografr_sims_abc demografr_abc.abc store simulated summary statistics needed calling abc::postpr tol Tolerance argument required abc::postpr ... optional arguments passed abc::postpr","code":""},{"path":"https://bodkan.net/demografr/reference/select_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform selection between different ABC models — select_model","text":"Object class postpr demografr_postpr","code":""},{"path":"https://bodkan.net/demografr/reference/select_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform selection between different ABC models — select_model","text":"","code":"if (FALSE) { # \\dontrun{ # read a list of three different ABC models models <- lapply(c(\"X\", \"Y\", \"Z\"), function(i) { readRDS(url(paste0( \"raw.githubusercontent.com/bodkan/demografr/refs/heads/main/inst/examples/downstream_abc\", i, \".rds\" ))) })  modsel <- select_model(models, tol = 0.03, method = \"neuralnet\") modsel } # }"},{"path":"https://bodkan.net/demografr/reference/simulate_abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data for ABC inference using specified priors — simulate_abc","title":"Simulate data for ABC inference using specified priors — simulate_abc","text":"core function ABC inference using demografr. generates simulation replicates computes summary statistic next step inference procedure, ABC estimation .","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data for ABC inference using specified priors — simulate_abc","text":"","code":"simulate_abc(   model,   priors,   functions,   observed,   iterations,   sequence_length,   recombination_rate,   mutation_rate = 0,   data = NULL,   format = c(\"ts\", \"files\"),   file = NULL,   packages = NULL,   attempts = 1000,   engine = NULL,   model_args = NULL,   engine_args = NULL )"},{"path":"https://bodkan.net/demografr/reference/simulate_abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data for ABC inference using specified priors — simulate_abc","text":"model Either slendr model generating function (case engine must either \"msprime\" \"slim\", .e. one two slendr's simulation back ends), path custom user-defined SLiM msprime script (case engine must \"custom\"). priors list prior distributions use sampling model parameters functions named list summary statistic functions apply simulated tree sequences observed named list observed summary statistics iterations many simulation replicates run? sequence_length Amount sequence simulate using slendr (numbers basepairs) recombination_rate Recombination rate use simulation mutation_rate Mutation rate use simulation data named list data-generating functions. names represent possible arguments simulated summary statistic functions. format format model generate results used computing simulated summary statistics? file NULL, path save data frame simulated grid results packages character vector package names used user-defined summary statistic functions. relevant parallelization set using future::plan() make sure parallelized tree-sequence summary statistic functions packages available. attempts Maximum number attempts generate prior values valid demographic model (default 1000) engine simulation engine use? Values \"msprime\" \"slim\" use one built-slendr simulation back ends. engine used determined nature model. engine = NULL, spatial slendr models default use \"slim\" back end, non-spatial models use \"msprime\" back end, custom user-defined model scripts use \"custom\" engine. Setting argument explicitly change back ends (appropriate). Setting argument custom simulation script effect. model_args Optional (non-prior) arguments slendr model generating function. Setting argument custom simulation script effect. engine_args Optional arguments slendr simulation back end. Setting argument custom simulation script effect.","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data for ABC inference using specified priors — simulate_abc","text":"list object class demografr_abc_sims containing results   ABC simulations, sampled parameters, priors, tree-sequence summary statistics","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data for ABC inference using specified priors — simulate_abc","text":"","code":"slendr::check_dependencies(python = TRUE, quit = TRUE)  library(demografr)  library(slendr) init_env(quiet = TRUE)  ################################################## # define a model  model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {   A <- population(\"A\", time = 1,    N = Ne_A)   B <- population(\"B\", time = T_AB, N = Ne_B, parent = A)   C <- population(\"C\", time = T_BC, N = Ne_C, parent = B)   D <- population(\"D\", time = T_CD, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf_BC)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\", serialize = FALSE   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 25), list(B, 25), list(C, 25), list(D, 25),     strict = TRUE   )    # when a specific sampling schedule is to be used, both model and samples   # must be returned by the function   return(list(model, samples)) }  ################################################## # set up priors  priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )  ################################################## # prepare a list of empirical summary statistics  observed_diversity <- read.table(   system.file(\"examples/basics_diversity.tsv\", package = \"demografr\"),   header = TRUE ) observed_divergence <- read.table(   system.file(\"examples/basics_divergence.tsv\", package = \"demografr\"),   header = TRUE ) observed_f4  <- read.table(   system.file(\"examples/basics_f4.tsv\", package = \"demografr\"),   header = TRUE ) observed <- list(   diversity  = observed_diversity,   divergence = observed_divergence,   f4         = observed_f4  )  ################################################## # prepare a list of simulated summary statistics  compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) } compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) } compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  functions <- list(   diversity  = compute_diversity,   divergence = compute_divergence,   f4         = compute_f4 )  ################################################## # simulate data from a single model run # (step #1 of a single ABC replicate simulation)  ts <- simulate_model(model, priors, sequence_length = 1e6, recombination_rate = 1e-8)  ################################################## # simulate data from a single model run # (step #2 of a single ABC replicate simulation)  summarise_data(ts, functions) #> $diversity #> # A tibble: 4 × 2 #>   set   diversity #>   <chr>     <dbl> #> 1 A             0 #> 2 B             0 #> 3 C             0 #> 4 D             0 #>  #> $divergence #> # A tibble: 6 × 3 #>   x     y     divergence #>   <chr> <chr>      <dbl> #> 1 A     B              0 #> 2 A     C              0 #> 3 A     D              0 #> 4 B     C              0 #> 5 B     D              0 #> 6 C     D              0 #>  #> $f4 #> # A tibble: 1 × 5 #>   W     X     Y     Z        f4 #>   <chr> <chr> <chr> <chr> <dbl> #> 1 A     B     C     D         0 #>   ################################################## # validate all components of the ABC inference pipeline  validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 1e-8) #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne_A ✅ #>   - Ne_B ✅ #>   - Ne_C ✅ #>   - Ne_D ✅ #>   - T_AB ✅ #>   - T_BC ✅ #>   - T_CD ✅ #>   - gf_BC ✅ #> --------------------------------------------------------------------- #> The model is a slendr function #> --------------------------------------------------------------------- #> Checking the return statement of the model function... ✅ #> --------------------------------------------------------------------- #> Checking the presence of required model function arguments...--------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #>   - divergence ✅ #>   - f4 ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #>   - divergence [data frame] ✅ #>   - f4 [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup!  # # we're skipping the remaining steps because they are extremely # computationally intensive for the scope of this example #  ################################################## # set up paralelization  # library(future) # plan(multisession, workers = availableCores())  ################################################## # simulate data (summary statistics)  # data <- simulate_abc( #   model, priors, functions, observed, iterations = 10000, #   sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8 # )  ################################################## # perform ABC inference  # abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/reference/simulate_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate values of summary statistics across a parameter grid — simulate_grid","title":"Simulate values of summary statistics across a parameter grid — simulate_grid","text":"given data frame (column parameter slendr model function) simulates values given population genetic statistics","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate values of summary statistics across a parameter grid — simulate_grid","text":"","code":"simulate_grid(   model,   grid,   functions,   replicates,   sequence_length,   recombination_rate,   mutation_rate = 0,   data = NULL,   format = c(\"ts\", \"files\"),   packages = NULL,   file = NULL,   engine = NULL,   model_args = NULL,   engine_args = NULL,   strict = TRUE )"},{"path":"https://bodkan.net/demografr/reference/simulate_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate values of summary statistics across a parameter grid — simulate_grid","text":"model slendr model generating function grid data frame object containing parameter grid one produced tidyr::expand_grid base::expand.grid functions named list summary statistic functions apply simulated tree sequences replicates many simulation replicates run parameter combination? sequence_length Amount sequence simulate using slendr (base pairs). Ignored custom simulations scripts provided. recombination_rate Recombination rate use simulation mutation_rate Mutation rate use simulation data named list data-generating functions. names represent possible arguments simulated summary statistic functions. format format model generate results used computing simulated summary statistics? packages character vector package names used user-defined summary statistic functions. relevant parallelization set using future::plan() make sure parallelized tree-sequence summary statistic functions packages available. file NULL, path save data frame simulated grid results. path set, results data frame returned invisibly. engine simulation engine use? Values \"msprime\" \"slim\" use one built-slendr simulation back ends. engine used determined nature model. engine = NULL, spatial slendr models default use \"slim\" back end, non-spatial models use \"msprime\" back end, custom user-defined model scripts use \"custom\" engine. Setting argument explicitly change back ends (appropriate). Setting argument custom simulation script effect. model_args Optional (non-prior) arguments slendr model generating function. Setting argument custom simulation script effect. engine_args Optional arguments slendr simulation back end. Setting argument custom simulation script effect. strict parameter combinations leading invalid slendr models treated error? Default TRUE. set FALSE, invalid simulations simply dropped, informative message.","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate values of summary statistics across a parameter grid — simulate_grid","text":"file != NULL, returns data frame simulated grid results. Otherwise   return anything, saving object .rds file instead. data frame object results parameter grid simulations, values  summary statistic stored list-column","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a single tree sequence from the given inference setup — simulate_model","title":"Simulate a single tree sequence from the given inference setup — simulate_model","text":"Simulates tree sequence object model parameters specified either sampling priors given list fixed parameter values","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a single tree sequence from the given inference setup — simulate_model","text":"","code":"simulate_model(   model,   parameters,   sequence_length,   recombination_rate,   mutation_rate = 0,   data = NULL,   format = c(\"ts\", \"files\"),   engine = NULL,   model_args = NULL,   engine_args = NULL,   attempts = 1000 )"},{"path":"https://bodkan.net/demografr/reference/simulate_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a single tree sequence from the given inference setup — simulate_model","text":"model Either slendr model generating function (case engine must either \"msprime\" \"slim\", .e. one two slendr's simulation back ends), path custom user-defined SLiM msprime script (case engine must \"files\"). parameters list prior distributions use sampling model parameters sequence_length Amount sequence simulate using slendr (base pairs). Ignored custom simulations scripts provided. recombination_rate Recombination rate use simulation Ignored custom simulations scripts provided. mutation_rate Mutation rate use simulation Ignored custom simulations scripts provided. data named list data-generating functions. names represent possible arguments simulated summary statistic functions. format format model generate results used computing simulated summary statistics? engine simulation engine use? Values \"msprime\" \"slim\" use one built-slendr simulation back ends. engine used determined nature model. engine = NULL, spatial slendr models default use \"slim\" back end, non-spatial models use \"msprime\" back end, custom user-defined model scripts use \"custom\" engine. Setting argument explicitly change back ends (appropriate). Setting argument custom simulation script effect. model_args Optional (non-prior) arguments slendr model generating function. Setting argument custom simulation script effect. engine_args Optional arguments slendr simulation back end. Setting argument custom simulation script effect. attempts Maximum number attempts generate prior values valid demographic model (.e. model generates output without error, default 1000)","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a single tree sequence from the given inference setup — simulate_model","text":"Either tree-sequence object class slendr_ts slendr model   simulated, path output file custom simulation script used.","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate a single tree sequence from the given inference setup — simulate_model","text":"function useful generate small tree sequence used developing summary statistic functions inference using demografr.","code":""},{"path":"https://bodkan.net/demografr/reference/simulate_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a single tree sequence from the given inference setup — simulate_model","text":"","code":"slendr::check_dependencies(python = TRUE, quit = TRUE)  library(demografr)  library(slendr) init_env(quiet = TRUE)  ################################################## # define a model  model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {   A <- population(\"A\", time = 1,    N = Ne_A)   B <- population(\"B\", time = T_AB, N = Ne_B, parent = A)   C <- population(\"C\", time = T_BC, N = Ne_C, parent = B)   D <- population(\"D\", time = T_CD, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf_BC)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\", serialize = FALSE   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 25), list(B, 25), list(C, 25), list(D, 25),     strict = TRUE   )    # when a specific sampling schedule is to be used, both model and samples   # must be returned by the function   return(list(model, samples)) }  ################################################## # set up priors  priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )  ################################################## # prepare a list of empirical summary statistics  observed_diversity <- read.table(   system.file(\"examples/basics_diversity.tsv\", package = \"demografr\"),   header = TRUE ) observed_divergence <- read.table(   system.file(\"examples/basics_divergence.tsv\", package = \"demografr\"),   header = TRUE ) observed_f4  <- read.table(   system.file(\"examples/basics_f4.tsv\", package = \"demografr\"),   header = TRUE ) observed <- list(   diversity  = observed_diversity,   divergence = observed_divergence,   f4         = observed_f4  )  ################################################## # prepare a list of simulated summary statistics  compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) } compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) } compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  functions <- list(   diversity  = compute_diversity,   divergence = compute_divergence,   f4         = compute_f4 )  ################################################## # simulate data from a single model run # (step #1 of a single ABC replicate simulation)  ts <- simulate_model(model, priors, sequence_length = 1e6, recombination_rate = 1e-8)  ################################################## # simulate data from a single model run # (step #2 of a single ABC replicate simulation)  summarise_data(ts, functions) #> $diversity #> # A tibble: 4 × 2 #>   set   diversity #>   <chr>     <dbl> #> 1 A             0 #> 2 B             0 #> 3 C             0 #> 4 D             0 #>  #> $divergence #> # A tibble: 6 × 3 #>   x     y     divergence #>   <chr> <chr>      <dbl> #> 1 A     B              0 #> 2 A     C              0 #> 3 A     D              0 #> 4 B     C              0 #> 5 B     D              0 #> 6 C     D              0 #>  #> $f4 #> # A tibble: 1 × 5 #>   W     X     Y     Z        f4 #>   <chr> <chr> <chr> <chr> <dbl> #> 1 A     B     C     D         0 #>   ################################################## # validate all components of the ABC inference pipeline  validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 1e-8) #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne_A ✅ #>   - Ne_B ✅ #>   - Ne_C ✅ #>   - Ne_D ✅ #>   - T_AB ✅ #>   - T_BC ✅ #>   - T_CD ✅ #>   - gf_BC ✅ #> --------------------------------------------------------------------- #> The model is a slendr function #> --------------------------------------------------------------------- #> Checking the return statement of the model function... ✅ #> --------------------------------------------------------------------- #> Checking the presence of required model function arguments...--------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #>   - divergence ✅ #>   - f4 ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #>   - divergence [data frame] ✅ #>   - f4 [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup!  # # we're skipping the remaining steps because they are extremely # computationally intensive for the scope of this example #  ################################################## # set up paralelization  # library(future) # plan(multisession, workers = availableCores())  ################################################## # simulate data (summary statistics)  # data <- simulate_abc( #   model, priors, functions, observed, iterations = 10000, #   sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8 # )  ################################################## # perform ABC inference  # abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/reference/summarise_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply summary statistic functions to the simulated data — summarise_data","title":"Apply summary statistic functions to the simulated data — summarise_data","text":"Apply summary statistic functions simulated data","code":""},{"path":"https://bodkan.net/demografr/reference/summarise_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply summary statistic functions to the simulated data — summarise_data","text":"","code":"summarise_data(data, functions)"},{"path":"https://bodkan.net/demografr/reference/summarise_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply summary statistic functions to the simulated data — summarise_data","text":"data Data generated simulate_model. Either named list (custom data-generating functions used user-defined simulation output files) object class slendr_ts (standard tree-sequence-producing simulation ran slendr ). functions named list data-generating functions","code":""},{"path":"https://bodkan.net/demografr/reference/summarise_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply summary statistic functions to the simulated data — summarise_data","text":"named list data frames, one summary statistic ","code":""},{"path":"https://bodkan.net/demografr/reference/summarise_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply summary statistic functions to the simulated data — summarise_data","text":"","code":"slendr::check_dependencies(python = TRUE, quit = TRUE)  library(demografr)  library(slendr) init_env(quiet = TRUE)  ################################################## # define a model  model <- function(Ne_A, Ne_B, Ne_C, Ne_D, T_AB, T_BC, T_CD, gf_BC) {   A <- population(\"A\", time = 1,    N = Ne_A)   B <- population(\"B\", time = T_AB, N = Ne_B, parent = A)   C <- population(\"C\", time = T_BC, N = Ne_C, parent = B)   D <- population(\"D\", time = T_CD, N = Ne_D, parent = C)    gf <- gene_flow(from = B, to = C, start = 9000, end = 9301, rate = gf_BC)    model <- compile_model(     populations = list(A, B, C, D), gene_flow = gf,     generation_time = 1, simulation_length = 10000,     direction = \"forward\", serialize = FALSE   )    samples <- schedule_sampling(     model, times = 10000,     list(A, 25), list(B, 25), list(C, 25), list(D, 25),     strict = TRUE   )    # when a specific sampling schedule is to be used, both model and samples   # must be returned by the function   return(list(model, samples)) }  ################################################## # set up priors  priors <- list(   Ne_A  ~ runif(1000, 3000),   Ne_B  ~ runif(100,  1500),   Ne_C  ~ runif(5000, 10000),   Ne_D  ~ runif(2000, 7000),    T_AB  ~ runif(1,    4000),   T_BC  ~ runif(3000, 9000),   T_CD  ~ runif(5000, 10000),    gf_BC ~ runif(0, 0.3) )  ################################################## # prepare a list of empirical summary statistics  observed_diversity <- read.table(   system.file(\"examples/basics_diversity.tsv\", package = \"demografr\"),   header = TRUE ) observed_divergence <- read.table(   system.file(\"examples/basics_divergence.tsv\", package = \"demografr\"),   header = TRUE ) observed_f4  <- read.table(   system.file(\"examples/basics_f4.tsv\", package = \"demografr\"),   header = TRUE ) observed <- list(   diversity  = observed_diversity,   divergence = observed_divergence,   f4         = observed_f4  )  ################################################## # prepare a list of simulated summary statistics  compute_diversity <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_diversity(ts, sample_sets = samples) } compute_divergence <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   ts_divergence(ts, sample_sets = samples) } compute_f4 <- function(ts) {   samples <- ts_names(ts, split = \"pop\")   A <- samples[\"A\"]; B <- samples[\"B\"]   C <- samples[\"C\"]; D <- samples[\"D\"]   ts_f4(ts, A, B, C, D) }  functions <- list(   diversity  = compute_diversity,   divergence = compute_divergence,   f4         = compute_f4 )  ################################################## # simulate data from a single model run # (step #1 of a single ABC replicate simulation)  ts <- simulate_model(model, priors, sequence_length = 1e6, recombination_rate = 1e-8)  ################################################## # simulate data from a single model run # (step #2 of a single ABC replicate simulation)  summarise_data(ts, functions) #> $diversity #> # A tibble: 4 × 2 #>   set   diversity #>   <chr>     <dbl> #> 1 A             0 #> 2 B             0 #> 3 C             0 #> 4 D             0 #>  #> $divergence #> # A tibble: 6 × 3 #>   x     y     divergence #>   <chr> <chr>      <dbl> #> 1 A     B              0 #> 2 A     C              0 #> 3 A     D              0 #> 4 B     C              0 #> 5 B     D              0 #> 6 C     D              0 #>  #> $f4 #> # A tibble: 1 × 5 #>   W     X     Y     Z        f4 #>   <chr> <chr> <chr> <chr> <dbl> #> 1 A     B     C     D         0 #>   ################################################## # validate all components of the ABC inference pipeline  validate_abc(model, priors, functions, observed,              sequence_length = 1e6, recombination_rate = 1e-8) #> ====================================================================== #> Testing sampling of each prior parameter: #>   - Ne_A ✅ #>   - Ne_B ✅ #>   - Ne_C ✅ #>   - Ne_D ✅ #>   - T_AB ✅ #>   - T_BC ✅ #>   - T_CD ✅ #>   - gf_BC ✅ #> --------------------------------------------------------------------- #> The model is a slendr function #> --------------------------------------------------------------------- #> Checking the return statement of the model function... ✅ #> --------------------------------------------------------------------- #> Checking the presence of required model function arguments...--------------------------------------------------------------------- #> Simulating tree sequence from the given model... ✅ #> --------------------------------------------------------------------- #> Computing user-defined summary functions: #>   - diversity ✅ #>   - divergence ✅ #>   - f4 ✅ #> --------------------------------------------------------------------- #> Checking the format of simulated summary statistics: #>   - diversity [data frame] ✅ #>   - divergence [data frame] ✅ #>   - f4 [data frame] ✅ #> ====================================================================== #> No issues have been found in the ABC setup!  # # we're skipping the remaining steps because they are extremely # computationally intensive for the scope of this example #  ################################################## # set up paralelization  # library(future) # plan(multisession, workers = availableCores())  ################################################## # simulate data (summary statistics)  # data <- simulate_abc( #   model, priors, functions, observed, iterations = 10000, #   sequence_length = 10e6, recombination_rate = 1e-8, mutation_rate = 1e-8 # )  ################################################## # perform ABC inference  # abc <- run_abc(data, engine = \"abc\", tol = 0.01, method = \"neuralnet\")"},{"path":"https://bodkan.net/demografr/reference/summary.demografr_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary results of the cv4postpr procedure from the abc R package — summary.demografr_cv","title":"Summary results of the cv4postpr procedure from the abc R package — summary.demografr_cv","text":"Summary results cv4postpr procedure abc R package","code":""},{"path":"https://bodkan.net/demografr/reference/summary.demografr_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary results of the cv4postpr procedure from the abc R package — summary.demografr_cv","text":"","code":"# S3 method for class 'demografr_cv' summary(object, ...)"},{"path":"https://bodkan.net/demografr/reference/summary.demografr_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary results of the cv4postpr procedure from the abc R package — summary.demografr_cv","text":"object ABC object generated run_abc ... Formal ellipsis argument summary method (unused)","code":""},{"path":"https://bodkan.net/demografr/reference/summary.demografr_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary results of the cv4postpr procedure from the abc R package — summary.demografr_cv","text":"...","code":""},{"path":"https://bodkan.net/demografr/reference/unpack.html","id":null,"dir":"Reference","previous_headings":"","what":"Unpack demografr object into individual components of the abc package — unpack","title":"Unpack demografr object into individual components of the abc package — unpack","text":"Unpack demografr object individual components abc package","code":""},{"path":"https://bodkan.net/demografr/reference/unpack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpack demografr object into individual components of the abc package — unpack","text":"","code":"unpack(object)"},{"path":"https://bodkan.net/demografr/reference/unpack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unpack demografr object into individual components of the abc package — unpack","text":"object demografr object decomposed individual components","code":""},{"path":"https://bodkan.net/demografr/reference/unpack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unpack demografr object into individual components of the abc package — unpack","text":"","code":"# read example ABC result with an inferred joint posterior distribution abc_res <- readRDS(system.file(\"examples/basics_abc.rds\", package = \"demografr\"))  # decompose the ABC object into components used by the abc R package parts <- unpack(abc_res) # the `parts` object is a plain R list of elements which can be used by # various functions of the underlying R package abc names(parts) #> [1] \"sumstat\" \"index\"   \"param\"   \"target\""},{"path":"https://bodkan.net/demografr/reference/validate_abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate individual components of an ABC model — validate_abc","title":"Validate individual components of an ABC model — validate_abc","text":"Validates ABC setup checking priors can correctly sampled , slendr model resulting priors can simulate tree sequence, user-defined summary functions produce output compatible provided empirical summary statistics.","code":""},{"path":"https://bodkan.net/demografr/reference/validate_abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate individual components of an ABC model — validate_abc","text":"","code":"validate_abc(   model,   priors,   functions,   observed,   sequence_length,   recombination_rate,   mutation_rate = 0,   format = c(\"ts\", \"files\"),   data = NULL,   engine = NULL,   model_args = NULL,   engine_args = NULL,   quiet = FALSE,   attempts = 1000 )"},{"path":"https://bodkan.net/demografr/reference/validate_abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate individual components of an ABC model — validate_abc","text":"model Either slendr model generating function (case engine must either \"msprime\" \"slim\", .e. one two slendr's simulation back ends), path custom user-defined SLiM msprime script (case engine must \"custom\"). priors list prior distributions use sampling model parameters functions named list summary statistic functions apply different simulated results (tree sequences custom files) observed named list observed summary statistics sequence_length Amount sequence simulate using slendr (base pairs). Ignored custom simulations scripts provided. recombination_rate Recombination rate use simulation mutation_rate Mutation rate use simulation format format model generate results used computing simulated summary statistics? data named list data-generating functions. names represent possible arguments simulated summary statistic functions. engine simulation engine use? Values \"msprime\" \"slim\" use one built-slendr simulation back ends. engine used determined nature model. engine = NULL, spatial slendr models default use \"slim\" back end, non-spatial models use \"msprime\" back end, custom user-defined model scripts use \"custom\" engine. Setting argument explicitly change back ends (appropriate). Setting argument custom simulation script effect. model_args Optional (non-prior) arguments slendr model generating function. Setting argument custom simulation script effect. engine_args Optional arguments slendr simulation back end. Setting argument custom simulation script effect. quiet log output validation printed console? (Default TRUE.) attempts Maximum number attempts generate prior values valid demographic model (default 1000)","code":""},{"path":"https://bodkan.net/demografr/reference/validate_abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate individual components of an ABC model — validate_abc","text":"return value. function ran terminal output.","code":""},{"path":"https://bodkan.net/demografr/news/index.html","id":"demografr-010","dir":"Changelog","previous_headings":"","what":"demografr 0.1.0","title":"demografr 0.1.0","text":"First CRAN release package (first release considered “public beta”).","code":""}]
